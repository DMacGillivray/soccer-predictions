{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0001.01 Data - Scope Football Data Co Uk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "# add the 'src' directory to path to import modules\n",
    "src_dir = pathlib.Path().cwd().resolve().parent / 'src'\n",
    "#src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "# import my class code from the source\n",
    "# %aimport src-dir.filename\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "PROJECT_DIR = pathlib.Path().cwd().resolve().parent\n",
    "\n",
    "RAW_DATA_DIR = PROJECT_DIR / 'data' / '01-raw'\n",
    "SCOPED_DATA_DIR = PROJECT_DIR / 'data' / '02-scoped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation Notes for football-data.co.uk Data Files\n",
    "\n",
    "\n",
    "[Interpretation Notes for football-data-co.uk data files](../data/reference/notes.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Top 16 European Leagues by Attendance\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_attendance_figures_at_domestic_professional_sports_leagues#Outdoor_sports\n",
    "\n",
    "Referenced on 30 November 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Raw Data Source, League and Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_data = {'nations': ['germany', 'england', 'spain', 'italy',\n",
    "          'france', 'england', 'germany', 'netherlands',\n",
    "          'russian-federation', 'scotland', 'portugal', 'switzerland',\n",
    "          'belgium', 'turkey', 'poland', 'england'],\n",
    "              'leagues': ['bundesliga', 'english-premier-league', 'la-liga', 'serie-a',\n",
    "           'ligue-1', 'english-championship', 'bundesliga-2', 'eredivisie',\n",
    "           'premier-league', 'premiership', 'primeira-liga', 'super-league',\n",
    "           'first-division-a', 'super-lig', 'ekstraklasa', 'one'],\n",
    "              'seasons': ['2000-2001', '2001-2002', '2002-2003', '2003-2004',\n",
    "           '2004-2005', '2005-2006', '2006-2007', '2007-2008',\n",
    "           '2008-2009', '2009-2010', '2010-2011', '2011-2012',\n",
    "           '2012-2013', '2013-2014', '2014-2015', '2015-2016',\n",
    "           '2016-2017', '2017-2018']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_fdcuk_load_fps(top_level_dir, scope_data):\n",
    "    \"\"\"\n",
    "    Accepts directory names to enable reach into raw data directory\n",
    "    Returns full filepaths of the data files\n",
    "    \"\"\"\n",
    "    fps = []\n",
    "    for nation, league in zip(scope_data['nations'], scope_data['leagues']):\n",
    "        for season in scope_data['seasons']:\n",
    "            fn = season + '.csv'\n",
    "            stub = RAW_DATA_DIR / 'football-data' / nation / league / season\n",
    "            fp = stub / 'football-data-co-uk' / 'season-data' / fn\n",
    "            if fp.exists():\n",
    "                fps.append(fp)\n",
    "    return fps\n",
    "\n",
    "def add_fdcuk_meta_data(df, fp):\n",
    "    strfp = str(fp)\n",
    "    season = fp.stem\n",
    "    nation=strfp.split('/')[11]\n",
    "    league = strfp.split('/')[12]\n",
    "    df['nation'] = nation\n",
    "    df['league'] = league\n",
    "    df['season'] = season\n",
    "    return df\n",
    "\n",
    "def read_badly_formed_csv_to_df(fp):\n",
    "    # https://stackoverflow.com/questions/55188544/pandas-how-to-workaround-error-tokenizing-data\n",
    "    # Skipping line 17: Expected 59 fields in line 17, saw 65\n",
    "    season_df = pd.read_csv(fp, header=None, sep='\\n', encoding=\"ISO-8859-1\")\n",
    "    season_df = season_df[0].str.split(',', expand=True)\n",
    "    season_df.columns = season_df.iloc[0]\n",
    "    season_df.drop([0], axis=0, inplace=True)\n",
    "    season_df = add_fdcuk_meta_data(season_df, fp)\n",
    "    season_df['bad'] = 1\n",
    "    return season_df\n",
    "\n",
    "    \n",
    "\n",
    "def load_fdcuk_fps_as_dfs(fdcuk_fps):   \n",
    "\n",
    "    good_season_dfs=[]\n",
    "    bad_season_dfs = []\n",
    "    for fp in fdcuk_fps:\n",
    "        try:\n",
    "            # Note: dayfirst=True\n",
    "            season_df = pd.read_csv(fp, dayfirst=True, parse_dates=['Date'],\n",
    "                                    engine='python', error_bad_lines=True, encoding=\"ISO-8859-1\")\n",
    "\n",
    "            season_df = add_fdcuk_meta_data(season_df, fp)\n",
    "            good_season_dfs.append(season_df)\n",
    "        except:\n",
    "            season_df = read_badly_formed_csv_to_df(fp)\n",
    "            bad_season_dfs.append(season_df)\n",
    "    \n",
    "    all_season_dfs = good_season_dfs + bad_season_dfs\n",
    "    return all_season_dfs\n",
    "\n",
    "\n",
    "\n",
    "def make_scoped_save_fps(top_level_dir, season_dfs, source = 'indatabet-com'):\n",
    "    \n",
    "    scoped_fdcuk_fps = []\n",
    "    for season_df in season_dfs:\n",
    "        nation = season_df['nation'].unique()[0]\n",
    "        league = season_df['league'].unique()[0]\n",
    "        season = season_df['season'].unique()[0]\n",
    "        fn = str(season) + '.csv'\n",
    "        save_fp = top_level_dir / source / nation / league / season / fn\n",
    "        scoped_fdcuk_fps.append(save_fp)\n",
    "    return scoped_fdcuk_fps\n",
    "\n",
    "\n",
    "def save_dfs_to_fps(dfs, fps):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    for df, fp in zip(dfs, fps):\n",
    "        if not fp.exists():\n",
    "            fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(fp, index=False)\n",
    "        n += 1\n",
    "    return n\n",
    "\n",
    "fdcuk_fps = make_fdcuk_load_fps(RAW_DATA_DIR, scope_data)\n",
    "all_season_dfs = load_fdcuk_fps_as_dfs(fdcuk_fps)\n",
    "scoped_fdcuk_fps = make_scoped_save_fps(SCOPED_DATA_DIR,\n",
    "                                           all_season_dfs,\n",
    "                                           source = 'football-data-co-uk')\n",
    "n_saved = save_dfs_to_fps(all_season_dfs, scoped_fdcuk_fps)\n",
    "n_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_season_dfs[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify scope of data for cleaning\n",
    "source = 'football-data'\n",
    "nation = 'united-kingdom'\n",
    "league = 'english-premier-league'\n",
    "seasons = ['2008-2009', '2009-2010', '2010-2011', '2011-2012', '2012-2013',\n",
    "           '2013-2014', '2014-2015', '2015-2016', '2016-2017', '2017-2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_fdcu_fps(RAW_DATA_DIR, source, nation, league, seasons):\n",
    "    \"\"\"\n",
    "    Accepts directory names to enable reach into raw data directory\n",
    "    Returns full filepaths of the data files\n",
    "    \"\"\"\n",
    "    fps = []\n",
    "    fdcu_specifics = ['football-data-co-uk', 'season-data']\n",
    "    for season in seasons:\n",
    "        fn = season + '.csv'\n",
    "        stub = RAW_DATA_DIR / source / nation / league / season\n",
    "        fp = stub / fdcu_specifics[0] / fdcu_specifics[1] / fn\n",
    "        #if fp.is_file():\n",
    "        if fp.exists():\n",
    "            fps.append(fp)\n",
    "    return fps\n",
    "\n",
    "fp = form_fdcu_fps(RAW_DATA_DIR, source, nation, league, seasons)\n",
    "fp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nations = ['germany', 'united-kingdom', 'spain', 'italy',\n",
    "          'france', 'united-kingdom', 'germany', 'netherlands',\n",
    "          'russian-federation', 'scotland', 'portugal', 'switzerland',\n",
    "          'belgium', 'turkey', 'poland', 'united-kingdom']\n",
    "\n",
    "# poland, switzerland are multileague\n",
    "\n",
    "leagues = ['bundesliga', 'english-premier-league', 'la-liga', 'serie-a',\n",
    "           'ligue-1', 'english-championship', 'bundesliga-2', 'eredivisie',\n",
    "           'premier-league', 'premiership', 'primeira-liga', 'super-league',\n",
    "           'first-division-a', 'super-lig', 'ekstraklasa', 'one']\n",
    "\n",
    "seasons = ['2000-2001', '2001-2002', '2002-2003', '2003-2004',\n",
    "           '2004-2005', '2005-2006', '2006-2007', '2007-2008',\n",
    "           '2008-2009', '2009-2010', '2010-2011', '2011-2012',\n",
    "           '2012-2013', '2013-2014', '2014-2015', '2015-2016',\n",
    "           '2016-2017', '2017-2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fps = []\n",
    "for nation, league in zip(nations, leagues):\n",
    "    fps = form_fdcu_fps(RAW_DATA_DIR, source, nation, league, seasons)\n",
    "    all_fps.extend(fps)\n",
    "\n",
    "print(len(all_fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_helper(fp, df):\n",
    "    strfp = str(fp)\n",
    "    season = fp.stem\n",
    "    nation=strfp.split('/')[11]\n",
    "    league = strfp.split('/')[12]\n",
    "    df['nation'] = nation\n",
    "    df['league'] = league\n",
    "    df['season'] = season\n",
    "    return df\n",
    "    \n",
    "    \n",
    "\n",
    "good_season_dfs=[]\n",
    "bad_season_dfs = []\n",
    "for fp in all_fps:\n",
    "\n",
    "    try:\n",
    "        # Note: dayfirst=True\n",
    "        season_df = pd.read_csv(fp, dayfirst=True, parse_dates=['Date'],\n",
    "                                engine='python', error_bad_lines=True, encoding=\"ISO-8859-1\")\n",
    "        season_df = read_helper(fp, season_df)\n",
    "        good_season_dfs.append(season_df)\n",
    "    except:\n",
    "        # https://stackoverflow.com/questions/55188544/pandas-how-to-workaround-error-tokenizing-data\n",
    "        # Skipping line 17: Expected 59 fields in line 17, saw 65\n",
    "        season_df = pd.read_csv(fp, header=None, sep='\\n', encoding=\"ISO-8859-1\")\n",
    "        season_df = season_df[0].str.split(',', expand=True)\n",
    "        season_df = read_helper(fp, season_df)\n",
    "        bad_season_dfs.append(season_df)\n",
    "\n",
    "df_orig = pd.concat(good_season_dfs, axis=0, sort=True)    \n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any columns that are all null\n",
    "df_orig = df_orig.dropna(axis=1, how='all')\n",
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_orig.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like there are differently named columns for the same thing\n",
    "# i.e Away, Away team and Home, Home Team\n",
    "# and for Goals AG and FTAG, and HG and FTHG\n",
    "df_orig['AwayTeam'] = df_orig['AwayTeam'].fillna(df_orig['Away'])\n",
    "df_orig['HomeTeam'] = df_orig['HomeTeam'].fillna(df_orig['Home'])\n",
    "df_orig['FTHG'] = df_orig['FTHG'].fillna(df_orig['HG'])\n",
    "df_orig['FTAG'] = df_orig['FTAG'].fillna(df_orig['AG'])\n",
    "df_orig['FTR'] = df_orig['FTR'].fillna(df_orig['Res'])\n",
    "\n",
    "df_orig['PSH'] = df_orig['PSH'].fillna(df_orig['PH'])\n",
    "df_orig['PSD'] = df_orig['PSD'].fillna(df_orig['PD'])\n",
    "df_orig['PSA'] = df_orig['PSA'].fillna(df_orig['PA'])\n",
    "\n",
    "\n",
    "df_orig[['league', 'AwayTeam', 'Away', 'HomeTeam', 'Home', 'FTHG', 'HG', 'FTAG', 'AG', 'FTR', 'Res']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df_orig.drop(columns=['Away', 'Home', 'HG', 'AG', 'Res'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like we have got some missing team names\n",
    "# If everything else is mt, these may be mt lines at the bottom of the csvs\n",
    "df_1 = df_orig[df_orig['AwayTeam'].isnull()]\n",
    "df_1.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are full of nans - Drop these\n",
    "df_2 = df_orig[~df_orig['AwayTeam'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we definitely do not want\n",
    "df_2 = df_2.drop(columns=['Attendance', 'Country', 'Div', 'Season', 'Time', 'ABP', 'HBP', 'Referee', 'HTR'])\n",
    "df_2 = df_2.sort_values(by=['nation', 'league', 'season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we definitely want to use better features than just goals\n",
    "# Definitely want to use Shots and Shots on target\n",
    "# These are coded as HS, AS, HST, AST\n",
    "msno.matrix(df_2[['HS', 'AS', 'HST', 'AST']])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pre-sorted by nation, league, season so it appears that the missing blocks are by season.\n",
    "# it also seems like there is less Shots on target data, than there is in the shots data, so, we will\n",
    "# Drop any season that have got missing values for HST, or AST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_dfs=[]\n",
    "for (nation, league, season), df in df_2.groupby(by=['nation', 'league', 'season']):\n",
    "    if df[['HST', 'AST']].isnull().sum().sum() == 0:\n",
    "          st_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut = pd.concat(st_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_3 = df_cut.copy(deep=True)\n",
    "df_3 = df_3.dropna(axis=1, how='all')\n",
    "df_3 = df_3.sort_values(by=['nation', 'league', 'season'])\n",
    "df_3.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like there are 42200 potential records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have sorted on nation., league and season\n",
    "# remove the full columns, and review how the nulls fit into the overall dataframe\n",
    "\n",
    "#df_null_cols = df_3[df_3.columns[df_3.isnull().any()]]\n",
    "msno.matrix(df_3)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_full_cols = df_3[df_3.columns[~df_3.isnull().any()]]\n",
    "df_3_full_cols.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be keeping all these so rename\n",
    "rename_d = {'AC': 'a_corners', 'AR': 'a_redCards', 'AS': 'a_shots', 'AST': 'a_shotsOnTarget',\n",
    "           'AY': 'a_yellowCards', 'AwayTeam': 'a',\n",
    "            'Date': 'date', 'FTAG': 'a_ftGoals', 'FTHG': 'h_ftGoals', 'FTR': 'ftResult',\n",
    "            'HC': 'h_corners', 'HR': 'h_redCards', 'HS': 'h_shots', 'HST': 'h_shotsOnTarget',\n",
    "            'HY': 'h_yellowCards', 'HomeTeam': 'h',\n",
    "           'HTAG': 'a_htGoals', 'HTHG': 'h_htGoals', 'AF': 'a_fouls', 'HF': 'h_fouls',\n",
    "           'HHW': 'h_woodWork', 'AHW': 'a_woodWork',\n",
    "           'AO': 'a_offsides', 'HO': 'h_offsides'}\n",
    "df_3 = df_3.rename(columns=rename_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_4 = df_3.copy(deep=True)\n",
    "# df_null_cols = df[df.columns[df.isnull().any()]]\n",
    "msno.matrix(df_4[df_4.columns[df_4.isnull().any()]])\n",
    "plt.show();   \n",
    "# for (nation, league, season), df in df_4.groupby(by=['nation', 'league', 'season']):\n",
    "#     print(nation, league, season)\n",
    "#     df_null_cols = df[df.columns[df.isnull().any()]]\n",
    "#     msno.matrix(df_null_cols, figsize=(14,2))\n",
    "#     plt.show();    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# take alook at the columns with any nulls\n",
    "# A full column has 42200 values\n",
    "my_cols = [col for col in df_4.columns if col not in list(rename_d.values())]\n",
    "df_5 = df_4[my_cols]\n",
    "df_5[df_5.columns[df_5.isnull().any()]].info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each game, it would be ideal if, as well as the match statistics, we could have\n",
    "# Mean odds, max odds, a full set of odds from a bookmaker, the closing odds\n",
    "# 42200 Games\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_dfs=[]\n",
    "for (nation, league, season), df in df_4.groupby(by=['nation', 'league', 'season']):\n",
    "    if df[['BbMxH', 'BbMxD', 'BbMxA', 'B365A', 'B365D', 'B365H']].isnull().sum().sum() == 0:\n",
    "          bb_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_6 = pd.concat(bb_dfs)\n",
    "df_6.info(verbose=True, null_counts=True)\n",
    "#df_6[df_6.columns[~df_6.isnull().any()]].info(verbose=True, null_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any columns with less than threshold\n",
    "thresh = int(len(df_6) * 0.75)\n",
    "df_7 = df_6.copy(deep=True)\n",
    "df_7 = df_7.dropna(axis=1, thresh=thresh)\n",
    "df_7.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_7, df_6[['PSCA', 'PSCD', 'PSCH']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if not col.startswith(('h', 'a'))]#'h' not in col[0:2] or 'a' not in col[0:1]]\n",
    "#or (col[0] != 'a')]\n",
    "print(sorted(cols))\n",
    "#df_7.columns#info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {'B365H': 'odds_hwin_bet365', 'B365D': 'odds_draw_bet365', 'B365A': 'odds_awin_bet365',\n",
    "            'BWH': 'odds_hwin_BW', 'BWD': 'odds_draw_BW', 'BWA': 'odds_awin_BW',\n",
    "            'Bb1X2': 'n_Bb1X2', 'BbAH': 'n_BbAsian', 'BbAHh': 'BbAsian_handicap',\n",
    "            'BbAv<2.5': 'odds_ftgoalsu2.5_bbmean', 'BbAv>2.5': 'odds_ftgoalso2.5_bbmean', \n",
    "            'BbAvA': 'odds_awin_bbmean',\n",
    "            'BbAvAHA': 'odds_asianaway_bbmean', 'BbAvAHH': 'odds_asianhome_bbmean',\n",
    "            'BbAvD': 'odds_draw_bbmean', 'BbAvH': 'odds_hwin_bbmean',\n",
    "            'BbMx<2.5': 'odds_ftgoalsu2.5_bbmax', 'BbMx>2.5': 'odds_ftgoalso2.5_bbmax',\n",
    "            'BbMxA': 'odds_awin_bbmax','BbMxAHA': 'odds_asianaway_bbmax', 'BbMxAHH': 'odds_asianhome_bbmax',\n",
    "            'BbMxD': 'odds_draw_bbmax', 'BbMxH': 'odds_hwin_bbmax', 'BbOU': 'n_BbOU',\n",
    "            'IWH': 'odds_hwin_IW', 'IWD': 'odds_draw_IW', 'IWA': 'odds_awin_IW',\n",
    "            'LBH': 'odds_hwin_LB', 'LBD': 'odds_draw_LB', 'LBA': 'odds_awin_LB',\n",
    "            'PSCH': 'clodds_hwin_pinn', 'PSCD': 'clodds_draw_pinn', 'PSCA': 'clodds_away_pinn',\n",
    "            'VCH': 'odds_hwin_VC', 'VCD': 'odds_draw_VC', 'VCA': 'odds_awin_VC', \n",
    "            'WHH': 'odds_hwin_WH', 'WHD': 'odds_draw_WH', 'WHA': 'odds_awin_WH'}\n",
    "df.rename(columns=columns, inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cols = df[df.columns[~df.isnull().any()]].columns\n",
    "list(full_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df[df.columns[df.isnull().any()]])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['league'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['season'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (nation, league, season), seas_df in df.groupby(by=['nation', 'league', 'season']):\n",
    "    season_df = seas_df.copy(deep=True)\n",
    "    season_df.sort_values(by=['date'], inplace=True)\n",
    "    season_df.reset_index(drop=True, inplace=True)\n",
    "    fn = season + '.csv'\n",
    "    source = 'football-data-co-uk'\n",
    "    save_dir = CLEANED_DIR / source / nation / league / season\n",
    "    save_fp = save_dir / fn\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    season_df.to_csv(save_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(save_fp, parse_dates=['date'], index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to clean up the data, we have to see all the seaons together, so we can see \n",
    "# what data is missing across the full scope of the data\n",
    "# Therefore, compile everything together and take a look\n",
    "leagues = ['english-premier-league', 'la-liga', 'bundesliga', 'serie-a', 'ligue-1', 'primeira-liga',\n",
    "           'russian-premier-league', 'ukranian-premier-league', 'eredivisie', 'superleague', 'super-lig',\n",
    "           'superliga', 'belgian-pro-league'\n",
    "all_fps = []\n",
    "for league in leagues:\n",
    "fps = form_fdcu_fps(RAW_DATA_DIR, source, nation, league, seasons)\n",
    "season_dfs=[]\n",
    "for season, fp in zip(seasons, fps):\n",
    "    # Note: dayfirst=True\n",
    "    season_df = pd.read_csv(fp, dayfirst=True, parse_dates=['Date'])\n",
    "    # Add the season to help navigate the merged dataframe\n",
    "    season_df['season'] = season\n",
    "    season_dfs.append(season_df)\n",
    "\n",
    "df = pd.concat(season_dfs, axis=0, sort=True)\n",
    "df = df.sort_values(by='Date')\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Complete, Partially Complete Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df[df.columns[~df.isnull().any()]]\n",
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_nulls = df[df.columns[df.isnull().any()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_with_nulls)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the data is missing based on the season\n",
    "# The Pinnacle closing odds data PSCA, PSCD, PSCH is missing for the first few seasons which is disappointing\n",
    "# But even with missing values, we will leave move this data onto the next stage\n",
    "# BbAH, BBAvAHA, BBAvAHH, BbMxAHA, and BbMXAHH have got more than 99% of their data \n",
    "# ie 3410/3420 = 0.997, so we will keep these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_threshold = 0.995\n",
    "# df.info().index\n",
    "# #droppers = ['BSA']\n",
    "df.dropna(thresh=df.shape[0]*0.6,how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_csv(INTERIM_DATA_DIR / league / save_file_name,\n",
    "                      parse_dates=['date'], index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first data file and take a look\n",
    "fp1 = form_fdcu_fps(RAW_DATA_DIR, source, nation, league, seasons)[0]\n",
    "fp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league = 'english-premier-league'\n",
    "GAME_DATA_DIR = RAW_DATA_DIR / 'football-data' / 'United-Kingdom' / league\n",
    "\n",
    "# seasons 2009-2010 through to 2017-2018\n",
    "start_year = 2009 ; end_year = 2018\n",
    "seasons = [str(year) + '-' + str(year+1) for year in range(start_year, end_year)]\n",
    "print(GAME_DATA_DIR)\n",
    "save_file_name = str('football-data-' + league + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Seasons into one file\n",
    "season_dfs=[]\n",
    "for season in seasons:\n",
    "    season_fp = GAME_DATA_DIR / season / 'football-data-co-uk' / 'season-data' / str(season + '.csv')\n",
    "#     season_dfs = pd.read_csv(season_fp)\n",
    "#     print(season_df.head())\n",
    "    season_df = pd.read_csv(season_fp, dayfirst=True, parse_dates=['Date'])\n",
    "    season_df['season'] = season\n",
    "    season_dfs.append(season_df)\n",
    "\n",
    "df = pd.concat(season_dfs, axis=0, sort=True)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df = df.copy(deep=True)\n",
    "\n",
    "# Drop unnecesary columns\n",
    "# Referee is not available for the full data set, and Half Time Result and Full Time Result can be calculated\n",
    "seasons_df.drop(columns=['Div', 'FTR', 'HTR', 'Referee', ], inplace=True)\n",
    "seasons_df.rename(columns={'Date': 'date', 'HomeTeam': 'h', 'AwayTeam': 'a',\n",
    "                          'FTHG': 'h_ftgoals', 'FTAG': 'a_ftgoals', 'HTHG': 'h_htgoals', 'HTAG': 'a_htgoals',\n",
    "                         'HS': 'h_shots', 'AS': 'a_shots', 'HST': 'h_sot', 'AST': 'a_sot',\n",
    "                         'HF': 'h_fouls', 'AF': 'a_fouls', 'HC': 'h_corners', 'AC': 'a_corners',\n",
    "                         'HY': 'h_ycards', 'AY': 'a_ycards', 'HR': 'h_rcards', 'AR': 'a_rcards'}, inplace=True)\n",
    "\n",
    "columns = {'B365H': 'odds_hwin_bet365', 'B365D': 'odds_draw_bet365', 'B365A': 'odds_awin_bet365',\n",
    "          'BWH': 'odds_hwin_BW', 'BWD': 'odds_draw_BW', 'BWA': 'odds_awin_BW',\n",
    "          'GBH': 'odds_hwin_GB', 'GBD': 'odds_draw_GB', 'GBA': 'odds_awin_GB',\n",
    "          'IWH': 'odds_hwin_IW', 'IWD': 'odds_draw_IW', 'IWA': 'odds_awin_IW',\n",
    "          'LBH': 'odds_hwin_LB', 'LBD': 'odds_draw_LB', 'LBA': 'odds_awin_LB',\n",
    "          'SBH': 'odds_hwin_SB', 'SBD': 'odds_draw_SB', 'SBA': 'odds_awin_SB',\n",
    "          'WHH': 'odds_hwin_WH', 'WHD': 'odds_draw_WH', 'WHA': 'odds_awin_WH',\n",
    "          'SJH': 'odds_hwin_SJ', 'SJD': 'odds_draw_SJ', 'SJA': 'odds_awin_SJ',\n",
    "          'VCH': 'odds_hwin_VC', 'VCD': 'odds_draw_VC', 'VCA': 'odds_awin_VC',           \n",
    "          'BSH': 'odds_hwin_BS', 'BSD': 'odds_draw_BS', 'BSA': 'odds_awin_BS',\n",
    "          'PSH': 'odds_hwin_pinn', 'PSD': 'odds_draw_pinn', 'PSA': 'odds_awin_pinn',\n",
    "           'Bb1X2': 'n_Bb1X2',\n",
    "           'BbMxH': 'odds_hwin_bbmax', 'BbMxD': 'odds_draw_bbmax', 'BbMxA': 'odds_awin_bbmax',\n",
    "           'BbAvH': 'odds_hwin_bbmean', 'BbAvD': 'odds_draw_bbmean', 'BbAvA': 'odds_awin_bbmean',\n",
    "           'BbOU': 'n_BbOU',\n",
    "           'BbMx>2.5': 'odds_ftgoalso2.5_bbmax', 'BbAv>2.5': 'odds_ftgoalso2.5_bbmean',\n",
    "           'BbMx<2.5': 'odds_ftgoalsu2.5_bbmax', 'BbAv<2.5': 'odds_ftgoalsu2.5_bbmean',\n",
    "           'BbAH': 'n_BbAsian',\n",
    "           'BbAHh': 'BbAsian_handicap',\n",
    "           'BbMxAHH': 'odds_asianhome_bbmax', 'BbAvAHH': 'odds_asianhome_bbmean',\n",
    "           'BbMxAHH': 'odds_asianhome_bbmax', 'BbAvAHH': 'odds_asianhome_bbmean',\n",
    "           'BbMxAHA': 'odds_asianaway_bbmax', 'BbAvAHH': 'odds_asianaway_bbmean',\n",
    "           'BbMxAHA': 'odds_asianaway_bbmax', 'BbAvAHA': 'odds_asianaway_bbmean',\n",
    "           'PSCH': 'clodds_hwin_pinn', 'PSCD': 'clodds_draw_pinn', 'PSCA': 'clodds_away_pinn'}\n",
    "seasons_df.rename(columns=columns, inplace=True)\n",
    "\n",
    "\n",
    "seasons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df.to_csv(INTERIM_DATA_DIR / league / save_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Back Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(INTERIM_DATA_DIR / league / save_file_name,\n",
    "                      parse_dates=['date'], index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
