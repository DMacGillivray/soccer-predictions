{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0001.01 Data - Scope indatabet-com Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyxlsb import open_workbook as open_xlsb\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "# add the 'src' directory to path to import modules\n",
    "src_dir = pathlib.Path().cwd().resolve().parent / 'src'\n",
    "#src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "# import my class code from the source\n",
    "# %aimport src-dir.filename\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "PROJECT_DIR = pathlib.Path().cwd().resolve().parent\n",
    "\n",
    "RAW_DATA_DIR = PROJECT_DIR / 'data' / '01-raw'\n",
    "SCOPED_DATA_DIR = PROJECT_DIR / 'data' / '02-scoped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation Notes for football-data.co.uk Data Files\n",
    "\n",
    "\n",
    "[Interpretation Notes for football-data-co.uk data files](../data/reference/notes.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Top 16 European Leagues by Attendance\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_attendance_figures_at_domestic_professional_sports_leagues#Outdoor_sports\n",
    "\n",
    "Referenced on 30 November 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Raw Data Source, League and Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_data = {'nations': ['germany', 'england', 'spain', 'italy',\n",
    "          'france', 'england', 'germany', 'netherlands',\n",
    "          'russian-federation', 'scotland', 'portugal', 'switzerland',\n",
    "          'belgium', 'turkey', 'poland', 'england'],\n",
    "              'leagues': ['bundesliga', 'english-premier-league', 'la-liga', 'serie-a',\n",
    "           'ligue-1', 'english-championship', 'bundesliga-2', 'eredivisie',\n",
    "           'premier-league', 'premiership', 'primeira-liga', 'super-league',\n",
    "           'first-division-a', 'super-lig', 'ekstraklasa', 'one'],\n",
    "              'seasons': ['2000-2001', '2001-2002', '2002-2003', '2003-2004',\n",
    "           '2004-2005', '2005-2006', '2006-2007', '2007-2008',\n",
    "           '2008-2009', '2009-2010', '2010-2011', '2011-2012',\n",
    "           '2012-2013', '2013-2014', '2014-2015', '2015-2016',\n",
    "           '2016-2017', '2017-2018']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_indatabet_fp(top_level_dir):\n",
    "    fp = top_level_dir / 'indatabet-free-download' / 'oOo FT_2in1_Pinnacle & bet365_ML TG_01 April 2019.xlsb'\n",
    "    return fp\n",
    "    \n",
    "def read_indatabet_monolithic_df(fp):\n",
    "    # https://stackoverflow.com/questions/45019778/read-xlsb-file-in-pandas-python\n",
    "    # Open xlsb file format\n",
    "    dfs = []\n",
    "\n",
    "    with open_xlsb(fp) as wb:\n",
    "        with wb.get_sheet(1) as sheet:\n",
    "            for row in sheet.rows():\n",
    "                dfs.append([item.v for item in row])\n",
    "\n",
    "    df = pd.DataFrame(dfs[1:], columns=dfs[0])\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_monolithic_df(df_orig):\n",
    "    \"\"\"\n",
    "    Have to do some cleaning in order to split\n",
    "    \"\"\"\n",
    "    df = df_orig.copy(deep=True)\n",
    "    \n",
    "    #df.columns = df.columns.str.lower()\n",
    "    \n",
    "    # Cutoff columns\n",
    "    df = df.iloc[:, 0:35]\n",
    "    # make column names strings\n",
    "    col_mapper = {col: str(col) for col in df.columns}\n",
    "    df.rename(columns = col_mapper, inplace=True)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Drop unnecessary columns\n",
    "    # Columns that can be calculated from other data such as Results goals over, under etc\n",
    "    # col 12 is first None | R | none\n",
    "    drop_cols = set([12,13,14,15, 16, 17, 20, 21, 26, 30])\n",
    "    all_cols = set(range(0, df.shape[1]))\n",
    "    keeper_cols = all_cols.difference(drop_cols)\n",
    "    df = df.iloc[:, list(keeper_cols)]\n",
    "    col_names = ['yy', 'dd', 'mm', 'date', 'id_fifa', 'country', 'league', 'season', 'h', 'a',\n",
    "                'h_htgoals', 'a_htgoals', 'h_ftGoals', 'a_ftGoals', 'et_pen_awd',\n",
    "                 'odds_hwin_pinn', 'odds_draw_pinn', 'odds_awin_pinn',\n",
    "                'odds_hwin_bet365', 'odds_draw_bet365', 'odds_awin_bet365',\n",
    "                'odds_ftgoalso2.5_pinn', 'odds_ftgoalsu2.5_pinn',\n",
    "                'odds_ftgoalso2.5_bet365', 'odds_ftgoalsu2.5_bet365']\n",
    "    df.columns = col_names\n",
    "    df = df.iloc[2:].reset_index(drop=True)\n",
    "    # Put seasons into my format\n",
    "    df['season'] = df['season'].str.replace('/', '-')\n",
    "    \n",
    "    # Format column data to lower case strings, replace  space with dash\n",
    "    str_cols = df.columns[(df.applymap(type) == str).all(0)]\n",
    "    for col in str_cols:\n",
    "        df[col] = df[col].str.strip().str.lower().str.replace(' ', '-')\n",
    "        \n",
    "    # Assemble date into common format - original date column cannot be trusted - multiple formats \n",
    "    df['date'] = pd.to_datetime(df['yy'].astype(int).astype(str) + '-' + df['mm'].astype(str)\n",
    "                                     + '-' + df['dd'].astype(int).astype(str))\n",
    "    df.drop(columns=['yy', 'dd', 'mm'], inplace=True)\n",
    "    df.sort_values(by='date', ascending=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "    \n",
    "def prep_monolithic_for_scoping(monolithic_df):\n",
    "    df = monolithic_df.copy(deep=True)\n",
    "    df.rename(columns={'country': 'nation'}, inplace=True)\n",
    "    \n",
    "    crit1 = df['nation'] == 'england'\n",
    "    crit2 = df['league'] == 'premier-league'\n",
    "    df.loc[crit1 & crit2, 'league'] = 'english-premier-league'\n",
    "\n",
    "    crit3 = df['league'] == 'championship'\n",
    "    df.loc[crit1 & crit3, 'league'] = 'english-championship'\n",
    "\n",
    "    crit4 = df['league'] == 'league-one'\n",
    "    df.loc[crit1 & crit4, 'league'] = 'one'\n",
    "\n",
    "    crit5 = df['nation'] == 'germany'\n",
    "    crit6 = df['league'] == '2.-bundesliga'\n",
    "    df.loc[crit5 & crit6, 'league'] = 'bundesliga-2'\n",
    "    \n",
    "    crit7 = df['nation'] == 'spain'\n",
    "    crit8 = df['league'] == 'primera-division'\n",
    "    df.loc[crit7 & crit8, 'league'] = 'la-liga'\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def scope_monolithic_df(monolithic_df, scope_data):\n",
    "    season_dfs = []\n",
    "    for nation, league in zip(scope_data['nations'], scope_data['leagues']):\n",
    "        for season in scope_data['seasons']:\n",
    "            crit1 = monolithic_df['nation'] == nation\n",
    "            crit2 = monolithic_df['league'] == league\n",
    "            crit3 = monolithic_df['season'] == season\n",
    "            season_df = monolithic_df[crit1 & crit2 & crit3]\n",
    "            if len(season_df):\n",
    "                season_dfs.append(season_df)\n",
    "    return season_dfs\n",
    "    \n",
    "def make_scoped_save_fps(top_level_dir, season_dfs, source = 'indatabet-com'):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!\n",
    "    \"\"\"\n",
    "    \n",
    "    scoped_fdcuk_fps = []\n",
    "    for season_df in season_dfs:\n",
    "        nation = season_df['nation'].unique()[0]\n",
    "        league = season_df['league'].unique()[0]\n",
    "        season = season_df['season'].unique()[0]\n",
    "        fn = str(season) + '.csv'\n",
    "        save_fp = top_level_dir / source / nation / league / season / fn\n",
    "        scoped_fdcuk_fps.append(save_fp)\n",
    "    return scoped_fdcuk_fps\n",
    "\n",
    "def save_dfs_to_fps(dfs, fps):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    for df, fp in zip(dfs, fps):\n",
    "        if not fp.exists():\n",
    "            fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(fp, index=False)\n",
    "        n += 1\n",
    "    return n\n",
    "    \n",
    "indatabet_fp = load_indatabet_fp(RAW_DATA_DIR)\n",
    "indatabet_monolithic_df = read_indatabet_monolithic_df(indatabet_fp)\n",
    "#indatabet_monolithic_df.head()\n",
    "clean_monolithic_df = clean_monolithic_df(indatabet_monolithic_df)\n",
    "#clean_monolithic_df.head()\n",
    "prepped_monolithic_df = prep_monolithic_for_scoping(clean_monolithic_df)\n",
    "#prepped_monolithic_df.head()\n",
    "scoped_dfs = scope_monolithic_df(prepped_monolithic_df, scope_data)\n",
    "#scoped_dfs[0].head()\n",
    "scoped_indatabet_fps = make_scoped_save_fps(SCOPED_DATA_DIR,\n",
    "                                            scoped_dfs,\n",
    "                                             source = 'indatabet-com')\n",
    "\n",
    "n_saved = save_dfs_to_fps(scoped_dfs, scoped_indatabet_fps)\n",
    "n_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_fifa</th>\n",
       "      <th>nation</th>\n",
       "      <th>league</th>\n",
       "      <th>season</th>\n",
       "      <th>h</th>\n",
       "      <th>a</th>\n",
       "      <th>h_htgoals</th>\n",
       "      <th>a_htgoals</th>\n",
       "      <th>h_ftGoals</th>\n",
       "      <th>a_ftGoals</th>\n",
       "      <th>et_pen_awd</th>\n",
       "      <th>odds_hwin_pinn</th>\n",
       "      <th>odds_draw_pinn</th>\n",
       "      <th>odds_awin_pinn</th>\n",
       "      <th>odds_hwin_bet365</th>\n",
       "      <th>odds_draw_bet365</th>\n",
       "      <th>odds_awin_bet365</th>\n",
       "      <th>odds_ftgoalso2.5_pinn</th>\n",
       "      <th>odds_ftgoalsu2.5_pinn</th>\n",
       "      <th>odds_ftgoalso2.5_bet365</th>\n",
       "      <th>odds_ftgoalsu2.5_bet365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195752</th>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>eng-d1</td>\n",
       "      <td>england</td>\n",
       "      <td>one</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>bradford</td>\n",
       "      <td>blackpool</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.78</td>\n",
       "      <td>5.31</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.81</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195755</th>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>eng-d1</td>\n",
       "      <td>england</td>\n",
       "      <td>one</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>southend</td>\n",
       "      <td>blackburn</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2.78</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195756</th>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>eng-d1</td>\n",
       "      <td>england</td>\n",
       "      <td>one</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>shrewsbury</td>\n",
       "      <td>northampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2.66</td>\n",
       "      <td>3.41</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195757</th>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>eng-d1</td>\n",
       "      <td>england</td>\n",
       "      <td>one</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>scunthorpe</td>\n",
       "      <td>afc-wimbledon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.61</td>\n",
       "      <td>4.46</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.81</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195758</th>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>eng-d1</td>\n",
       "      <td>england</td>\n",
       "      <td>one</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>portsmouth</td>\n",
       "      <td>rochdale</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.86</td>\n",
       "      <td>3.71</td>\n",
       "      <td>4.57</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.91</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date id_fifa   nation league     season           h              a h_htgoals a_htgoals h_ftGoals a_ftGoals et_pen_awd odds_hwin_pinn odds_draw_pinn odds_awin_pinn odds_hwin_bet365 odds_draw_bet365 odds_awin_bet365 odds_ftgoalso2.5_pinn odds_ftgoalsu2.5_pinn odds_ftgoalso2.5_bet365 odds_ftgoalsu2.5_bet365\n",
       "195752 2017-08-05  eng-d1  england    one  2017-2018    bradford      blackpool         1         1         2         1       None           1.75           3.78           5.31             1.62              3.8              5.5                  2.11                  1.81                    None                    None\n",
       "195755 2017-08-05  eng-d1  england    one  2017-2018    southend      blackburn         2         0         2         1       None           2.78           3.42           2.68             2.63              3.3             2.63                  2.04                  1.86                     1.9                     1.9\n",
       "195756 2017-08-05  eng-d1  england    one  2017-2018  shrewsbury    northampton         0         0         1         0       None           2.66           3.41           2.81              2.4              3.4              2.8                  2.08                  1.83                    1.93                    1.88\n",
       "195757 2017-08-05  eng-d1  england    one  2017-2018  scunthorpe  afc-wimbledon         1         0         1         1       None           1.91           3.61           4.46             1.91              3.4                4                   2.1                  1.81                    None                    None\n",
       "195758 2017-08-05  eng-d1  england    one  2017-2018  portsmouth       rochdale         0         0         2         0       None           1.86           3.71           4.57             1.73              3.5                5                  1.99                  1.91                    None                    None"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoped_dfs[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Europe', 'Japan', 'Brazil', 'Switzerland', 'France', 'England',\n",
       "       'Argentina', 'Turkey', 'Germany', 'Netherlands', 'Portugal',\n",
       "       'Italy', 'Spain', 'World', 'Republic of Ireland', 'USA', 'Norway',\n",
       "       'Sweden', 'Finland', 'Austria', 'Denmark', 'Scotland', 'Australia',\n",
       "       'Belgium', 'Greece', 'Poland', 'Iceland', 'Colombia', 'Ecuador',\n",
       "       'Russian Federation', 'China', 'Ukraine', 'Slovakia', 'Romania',\n",
       "       'Croatia', 'Mexico', 'Hungary', 'Egypt', 'Asia', 'Peru', 'Bolivia',\n",
       "       'Venezuela', 'Slovenia'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_monolithic_df['nation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_fifa</th>\n",
       "      <th>country</th>\n",
       "      <th>league</th>\n",
       "      <th>season</th>\n",
       "      <th>h</th>\n",
       "      <th>a</th>\n",
       "      <th>h_htgoals</th>\n",
       "      <th>a_htgoals</th>\n",
       "      <th>h_ftGoals</th>\n",
       "      <th>a_ftGoals</th>\n",
       "      <th>et_pen_awd</th>\n",
       "      <th>odds_hwin_pinn</th>\n",
       "      <th>odds_draw_pinn</th>\n",
       "      <th>odds_awin_pinn</th>\n",
       "      <th>odds_hwin_bet365</th>\n",
       "      <th>odds_draw_bet365</th>\n",
       "      <th>odds_awin_bet365</th>\n",
       "      <th>odds_ftgoalso2.5_pinn</th>\n",
       "      <th>odds_ftgoalsu2.5_pinn</th>\n",
       "      <th>odds_ftgoalso2.5_bet365</th>\n",
       "      <th>odds_ftgoalsu2.5_bet365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-08-16</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Euro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-09-02</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Euro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Liechtenstein</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.01</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-09-02</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Euro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>1.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-09-02</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Euro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moldova</td>\n",
       "      <td>Greece</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.57</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-09-02</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Euro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date id_fifa country league season           h              a h_htgoals a_htgoals h_ftGoals a_ftGoals et_pen_awd odds_hwin_pinn odds_draw_pinn odds_awin_pinn odds_hwin_bet365 odds_draw_bet365 odds_awin_bet365 odds_ftgoalso2.5_pinn odds_ftgoalsu2.5_pinn odds_ftgoalso2.5_bet365 odds_ftgoalsu2.5_bet365\n",
       "0 2006-08-16     EUR  Europe   Euro    NaN     Belgium     Kazakhstan         0         0         0         0       None           None           None           None              1.1                7               15                  None                  None                    None                    None\n",
       "1 2006-09-02     EUR  Europe   Euro    NaN       Spain  Liechtenstein         2         0         4         0       None           None           None           None             1.01               10               51                  None                  None                    None                    None\n",
       "2 2006-09-02     EUR  Europe   Euro    NaN  Luxembourg    Netherlands         0         1         0         1       None           None           None           None               51               10             1.01                  None                  None                    None                    None\n",
       "3 2006-09-02     EUR  Europe   Euro    NaN     Moldova         Greece         0         1         0         1       None           None           None           None                5              3.6             1.57                  None                  None                    None                    None\n",
       "4 2006-09-02     EUR  Europe   Euro    NaN      Serbia     Azerbaijan         0         0         1         0       None           None           None           None              1.1                7               15                  None                  None                    None                    None"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_monolithic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_fdcuk_load_fps(top_level_dir, scope_data):\n",
    "    \"\"\"\n",
    "    Accepts directory names to enable reach into raw data directory\n",
    "    Returns full filepaths of the data files\n",
    "    \"\"\"\n",
    "    fps = []\n",
    "    for nation, league in zip(scope_data['nations'], scope_data['leagues']):\n",
    "        for season in scope_data['seasons']:\n",
    "            fn = season + '.csv'\n",
    "            stub = RAW_DATA_DIR / 'football-data' / nation / league / season\n",
    "            fp = stub / 'football-data-co-uk' / 'season-data' / fn\n",
    "            if fp.exists():\n",
    "                fps.append(fp)\n",
    "    return fps\n",
    "\n",
    "def add_fdcuk_meta_data(df, fp):\n",
    "    strfp = str(fp)\n",
    "    season = fp.stem\n",
    "    nation=strfp.split('/')[11]\n",
    "    league = strfp.split('/')[12]\n",
    "    df['nation'] = nation\n",
    "    df['league'] = league\n",
    "    df['season'] = season\n",
    "    return df\n",
    "\n",
    "def read_badly_formed_csv_to_df(fp):\n",
    "    # https://stackoverflow.com/questions/55188544/pandas-how-to-workaround-error-tokenizing-data\n",
    "    # Skipping line 17: Expected 59 fields in line 17, saw 65\n",
    "    season_df = pd.read_csv(fp, header=None, sep='\\n', encoding=\"ISO-8859-1\")\n",
    "    season_df = season_df[0].str.split(',', expand=True)\n",
    "    season_df.columns = season_df.iloc[0]\n",
    "    season_df = add_fdcuk_meta_data(season_df, fp)\n",
    "    return season_df\n",
    "\n",
    "    \n",
    "\n",
    "def load_fdcuk_fps_as_dfs(fdcuk_fps):   \n",
    "\n",
    "    good_season_dfs=[]\n",
    "    bad_season_dfs = []\n",
    "    for fp in fdcuk_fps:\n",
    "        try:\n",
    "            # Note: dayfirst=True\n",
    "            season_df = pd.read_csv(fp, dayfirst=True, parse_dates=['Date'],\n",
    "                                    engine='python', error_bad_lines=True, encoding=\"ISO-8859-1\")\n",
    "\n",
    "            season_df = add_fdcuk_meta_data(season_df, fp)\n",
    "            good_season_dfs.append(season_df)\n",
    "        except:\n",
    "            season_df = read_badly_formed_csv_to_df(fp)\n",
    "            bad_season_dfs.append(season_df)\n",
    "    \n",
    "    all_season_dfs = good_season_dfs + bad_season_dfs\n",
    "    return all_season_dfs\n",
    "\n",
    "\n",
    "\n",
    "def make_scoped_save_fps(top_level_dir, fdcuk_fps, season_dfs, source = 'indatabet-com'):\n",
    "    \n",
    "    scoped_fdcuk_fps = []\n",
    "    for season_df in season_dfs:\n",
    "        nation = season_df['nation'].unique()[0]\n",
    "        league = season_df['league'].unique()[0]\n",
    "        season = season_df['season'].unique()[0]\n",
    "        fn = str(season) + '.csv'\n",
    "        save_fp = top_level_dir / source / nation / league / season / fn\n",
    "        scoped_fdcuk_fps.append(save_fp)\n",
    "    return scoped_fdcuk_fps\n",
    "\n",
    "\n",
    "def save_dfs_to_fps(dfs, fps):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    for df, fp in zip(dfs, fps):\n",
    "        if not fp.exists():\n",
    "            fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(fp, index=False)\n",
    "        n += 1\n",
    "    return n\n",
    "\n",
    "fdcuk_fps = make_fdcuk_load_fps(RAW_DATA_DIR, scope_data)\n",
    "all_season_dfs = load_fdcuk_fps_as_dfs(fdcuk_fps)\n",
    "scoped_fdcuk_fps = make_scoped_save_fps(SCOPED_DATA_DIR,\n",
    "                                           fdcuk_fps,\n",
    "                                           all_season_dfs,\n",
    "                                           source = 'football-data-co-uk')\n",
    "n_saved = save_dfs_to_fps(all_season_dfs, scoped_fdcuk_fps)\n",
    "n_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_season_dfs[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify scope of data for cleaning\n",
    "source = 'football-data'\n",
    "nation = 'united-kingdom'\n",
    "league = 'english-premier-league'\n",
    "seasons = ['2008-2009', '2009-2010', '2010-2011', '2011-2012', '2012-2013',\n",
    "           '2013-2014', '2014-2015', '2015-2016', '2016-2017', '2017-2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_fdcu_fps(RAW_DATA_DIR, source, nation, league, seasons):\n",
    "    \"\"\"\n",
    "    Accepts directory names to enable reach into raw data directory\n",
    "    Returns full filepaths of the data files\n",
    "    \"\"\"\n",
    "    fps = []\n",
    "    fdcu_specifics = ['football-data-co-uk', 'season-data']\n",
    "    for season in seasons:\n",
    "        fn = season + '.csv'\n",
    "        stub = RAW_DATA_DIR / source / nation / league / season\n",
    "        fp = stub / fdcu_specifics[0] / fdcu_specifics[1] / fn\n",
    "        #if fp.is_file():\n",
    "        if fp.exists():\n",
    "            fps.append(fp)\n",
    "    return fps\n",
    "\n",
    "fp = form_fdcu_fps(RAW_DATA_DIR, source, nation, league, seasons)\n",
    "fp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nations = ['germany', 'united-kingdom', 'spain', 'italy',\n",
    "          'france', 'united-kingdom', 'germany', 'netherlands',\n",
    "          'russian-federation', 'scotland', 'portugal', 'switzerland',\n",
    "          'belgium', 'turkey', 'poland', 'united-kingdom']\n",
    "\n",
    "# poland, switzerland are multileague\n",
    "\n",
    "leagues = ['bundesliga', 'english-premier-league', 'la-liga', 'serie-a',\n",
    "           'ligue-1', 'english-championship', 'bundesliga-2', 'eredivisie',\n",
    "           'premier-league', 'premiership', 'primeira-liga', 'super-league',\n",
    "           'first-division-a', 'super-lig', 'ekstraklasa', 'one']\n",
    "\n",
    "seasons = ['2000-2001', '2001-2002', '2002-2003', '2003-2004',\n",
    "           '2004-2005', '2005-2006', '2006-2007', '2007-2008',\n",
    "           '2008-2009', '2009-2010', '2010-2011', '2011-2012',\n",
    "           '2012-2013', '2013-2014', '2014-2015', '2015-2016',\n",
    "           '2016-2017', '2017-2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fps = []\n",
    "for nation, league in zip(nations, leagues):\n",
    "    fps = form_fdcu_fps(RAW_DATA_DIR, source, nation, league, seasons)\n",
    "    all_fps.extend(fps)\n",
    "\n",
    "print(len(all_fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_helper(fp, df):\n",
    "    strfp = str(fp)\n",
    "    season = fp.stem\n",
    "    nation=strfp.split('/')[11]\n",
    "    league = strfp.split('/')[12]\n",
    "    df['nation'] = nation\n",
    "    df['league'] = league\n",
    "    df['season'] = season\n",
    "    return df\n",
    "    \n",
    "    \n",
    "\n",
    "good_season_dfs=[]\n",
    "bad_season_dfs = []\n",
    "for fp in all_fps:\n",
    "\n",
    "    try:\n",
    "        # Note: dayfirst=True\n",
    "        season_df = pd.read_csv(fp, dayfirst=True, parse_dates=['Date'],\n",
    "                                engine='python', error_bad_lines=True, encoding=\"ISO-8859-1\")\n",
    "        season_df = read_helper(fp, season_df)\n",
    "        good_season_dfs.append(season_df)\n",
    "    except:\n",
    "        # https://stackoverflow.com/questions/55188544/pandas-how-to-workaround-error-tokenizing-data\n",
    "        # Skipping line 17: Expected 59 fields in line 17, saw 65\n",
    "        season_df = pd.read_csv(fp, header=None, sep='\\n', encoding=\"ISO-8859-1\")\n",
    "        season_df = season_df[0].str.split(',', expand=True)\n",
    "        season_df = read_helper(fp, season_df)\n",
    "        bad_season_dfs.append(season_df)\n",
    "\n",
    "df_orig = pd.concat(good_season_dfs, axis=0, sort=True)    \n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any columns that are all null\n",
    "df_orig = df_orig.dropna(axis=1, how='all')\n",
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_orig.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like there are differently named columns for the same thing\n",
    "# i.e Away, Away team and Home, Home Team\n",
    "# and for Goals AG and FTAG, and HG and FTHG\n",
    "df_orig['AwayTeam'] = df_orig['AwayTeam'].fillna(df_orig['Away'])\n",
    "df_orig['HomeTeam'] = df_orig['HomeTeam'].fillna(df_orig['Home'])\n",
    "df_orig['FTHG'] = df_orig['FTHG'].fillna(df_orig['HG'])\n",
    "df_orig['FTAG'] = df_orig['FTAG'].fillna(df_orig['AG'])\n",
    "df_orig['FTR'] = df_orig['FTR'].fillna(df_orig['Res'])\n",
    "\n",
    "df_orig['PSH'] = df_orig['PSH'].fillna(df_orig['PH'])\n",
    "df_orig['PSD'] = df_orig['PSD'].fillna(df_orig['PD'])\n",
    "df_orig['PSA'] = df_orig['PSA'].fillna(df_orig['PA'])\n",
    "\n",
    "\n",
    "df_orig[['league', 'AwayTeam', 'Away', 'HomeTeam', 'Home', 'FTHG', 'HG', 'FTAG', 'AG', 'FTR', 'Res']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df_orig.drop(columns=['Away', 'Home', 'HG', 'AG', 'Res'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like we have got some missing team names\n",
    "# If everything else is mt, these may be mt lines at the bottom of the csvs\n",
    "df_1 = df_orig[df_orig['AwayTeam'].isnull()]\n",
    "df_1.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are full of nans - Drop these\n",
    "df_2 = df_orig[~df_orig['AwayTeam'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we definitely do not want\n",
    "df_2 = df_2.drop(columns=['Attendance', 'Country', 'Div', 'Season', 'Time', 'ABP', 'HBP', 'Referee', 'HTR'])\n",
    "df_2 = df_2.sort_values(by=['nation', 'league', 'season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we definitely want to use better features than just goals\n",
    "# Definitely want to use Shots and Shots on target\n",
    "# These are coded as HS, AS, HST, AST\n",
    "msno.matrix(df_2[['HS', 'AS', 'HST', 'AST']])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pre-sorted by nation, league, season so it appears that the missing blocks are by season.\n",
    "# it also seems like there is less Shots on target data, than there is in the shots data, so, we will\n",
    "# Drop any season that have got missing values for HST, or AST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_dfs=[]\n",
    "for (nation, league, season), df in df_2.groupby(by=['nation', 'league', 'season']):\n",
    "    if df[['HST', 'AST']].isnull().sum().sum() == 0:\n",
    "          st_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut = pd.concat(st_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_3 = df_cut.copy(deep=True)\n",
    "df_3 = df_3.dropna(axis=1, how='all')\n",
    "df_3 = df_3.sort_values(by=['nation', 'league', 'season'])\n",
    "df_3.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like there are 42200 potential records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have sorted on nation., league and season\n",
    "# remove the full columns, and review how the nulls fit into the overall dataframe\n",
    "\n",
    "#df_null_cols = df_3[df_3.columns[df_3.isnull().any()]]\n",
    "msno.matrix(df_3)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_full_cols = df_3[df_3.columns[~df_3.isnull().any()]]\n",
    "df_3_full_cols.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be keeping all these so rename\n",
    "rename_d = {'AC': 'a_corners', 'AR': 'a_redCards', 'AS': 'a_shots', 'AST': 'a_shotsOnTarget',\n",
    "           'AY': 'a_yellowCards', 'AwayTeam': 'a',\n",
    "            'Date': 'date', 'FTAG': 'a_ftGoals', 'FTHG': 'h_ftGoals', 'FTR': 'ftResult',\n",
    "            'HC': 'h_corners', 'HR': 'h_redCards', 'HS': 'h_shots', 'HST': 'h_shotsOnTarget',\n",
    "            'HY': 'h_yellowCards', 'HomeTeam': 'h',\n",
    "           'HTAG': 'a_htGoals', 'HTHG': 'h_htGoals', 'AF': 'a_fouls', 'HF': 'h_fouls',\n",
    "           'HHW': 'h_woodWork', 'AHW': 'a_woodWork',\n",
    "           'AO': 'a_offsides', 'HO': 'h_offsides'}\n",
    "df_3 = df_3.rename(columns=rename_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_4 = df_3.copy(deep=True)\n",
    "# df_null_cols = df[df.columns[df.isnull().any()]]\n",
    "msno.matrix(df_4[df_4.columns[df_4.isnull().any()]])\n",
    "plt.show();   \n",
    "# for (nation, league, season), df in df_4.groupby(by=['nation', 'league', 'season']):\n",
    "#     print(nation, league, season)\n",
    "#     df_null_cols = df[df.columns[df.isnull().any()]]\n",
    "#     msno.matrix(df_null_cols, figsize=(14,2))\n",
    "#     plt.show();    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# take alook at the columns with any nulls\n",
    "# A full column has 42200 values\n",
    "my_cols = [col for col in df_4.columns if col not in list(rename_d.values())]\n",
    "df_5 = df_4[my_cols]\n",
    "df_5[df_5.columns[df_5.isnull().any()]].info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each game, it would be ideal if, as well as the match statistics, we could have\n",
    "# Mean odds, max odds, a full set of odds from a bookmaker, the closing odds\n",
    "# 42200 Games\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_dfs=[]\n",
    "for (nation, league, season), df in df_4.groupby(by=['nation', 'league', 'season']):\n",
    "    if df[['BbMxH', 'BbMxD', 'BbMxA', 'B365A', 'B365D', 'B365H']].isnull().sum().sum() == 0:\n",
    "          bb_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_6 = pd.concat(bb_dfs)\n",
    "df_6.info(verbose=True, null_counts=True)\n",
    "#df_6[df_6.columns[~df_6.isnull().any()]].info(verbose=True, null_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any columns with less than threshold\n",
    "thresh = int(len(df_6) * 0.75)\n",
    "df_7 = df_6.copy(deep=True)\n",
    "df_7 = df_7.dropna(axis=1, thresh=thresh)\n",
    "df_7.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_7, df_6[['PSCA', 'PSCD', 'PSCH']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if not col.startswith(('h', 'a'))]#'h' not in col[0:2] or 'a' not in col[0:1]]\n",
    "#or (col[0] != 'a')]\n",
    "print(sorted(cols))\n",
    "#df_7.columns#info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {'B365H': 'odds_hwin_bet365', 'B365D': 'odds_draw_bet365', 'B365A': 'odds_awin_bet365',\n",
    "            'BWH': 'odds_hwin_BW', 'BWD': 'odds_draw_BW', 'BWA': 'odds_awin_BW',\n",
    "            'Bb1X2': 'n_Bb1X2', 'BbAH': 'n_BbAsian', 'BbAHh': 'BbAsian_handicap',\n",
    "            'BbAv<2.5': 'odds_ftgoalsu2.5_bbmean', 'BbAv>2.5': 'odds_ftgoalso2.5_bbmean', \n",
    "            'BbAvA': 'odds_awin_bbmean',\n",
    "            'BbAvAHA': 'odds_asianaway_bbmean', 'BbAvAHH': 'odds_asianhome_bbmean',\n",
    "            'BbAvD': 'odds_draw_bbmean', 'BbAvH': 'odds_hwin_bbmean',\n",
    "            'BbMx<2.5': 'odds_ftgoalsu2.5_bbmax', 'BbMx>2.5': 'odds_ftgoalso2.5_bbmax',\n",
    "            'BbMxA': 'odds_awin_bbmax','BbMxAHA': 'odds_asianaway_bbmax', 'BbMxAHH': 'odds_asianhome_bbmax',\n",
    "            'BbMxD': 'odds_draw_bbmax', 'BbMxH': 'odds_hwin_bbmax', 'BbOU': 'n_BbOU',\n",
    "            'IWH': 'odds_hwin_IW', 'IWD': 'odds_draw_IW', 'IWA': 'odds_awin_IW',\n",
    "            'LBH': 'odds_hwin_LB', 'LBD': 'odds_draw_LB', 'LBA': 'odds_awin_LB',\n",
    "            'PSCH': 'clodds_hwin_pinn', 'PSCD': 'clodds_draw_pinn', 'PSCA': 'clodds_away_pinn',\n",
    "            'VCH': 'odds_hwin_VC', 'VCD': 'odds_draw_VC', 'VCA': 'odds_awin_VC', \n",
    "            'WHH': 'odds_hwin_WH', 'WHD': 'odds_draw_WH', 'WHA': 'odds_awin_WH'}\n",
    "df.rename(columns=columns, inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cols = df[df.columns[~df.isnull().any()]].columns\n",
    "list(full_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df[df.columns[df.isnull().any()]])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['league'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['season'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (nation, league, season), seas_df in df.groupby(by=['nation', 'league', 'season']):\n",
    "    season_df = seas_df.copy(deep=True)\n",
    "    season_df.sort_values(by=['date'], inplace=True)\n",
    "    season_df.reset_index(drop=True, inplace=True)\n",
    "    fn = season + '.csv'\n",
    "    source = 'football-data-co-uk'\n",
    "    save_dir = CLEANED_DIR / source / nation / league / season\n",
    "    save_fp = save_dir / fn\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    season_df.to_csv(save_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(save_fp, parse_dates=['date'], index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to clean up the data, we have to see all the seaons together, so we can see \n",
    "# what data is missing across the full scope of the data\n",
    "# Therefore, compile everything together and take a look\n",
    "leagues = ['english-premier-league', 'la-liga', 'bundesliga', 'serie-a', 'ligue-1', 'primeira-liga',\n",
    "           'russian-premier-league', 'ukranian-premier-league', 'eredivisie', 'superleague', 'super-lig',\n",
    "           'superliga', 'belgian-pro-league'\n",
    "all_fps = []\n",
    "for league in leagues:\n",
    "fps = form_fdcu_fps(RAW_DATA_DIR, source, nation, league, seasons)\n",
    "season_dfs=[]\n",
    "for season, fp in zip(seasons, fps):\n",
    "    # Note: dayfirst=True\n",
    "    season_df = pd.read_csv(fp, dayfirst=True, parse_dates=['Date'])\n",
    "    # Add the season to help navigate the merged dataframe\n",
    "    season_df['season'] = season\n",
    "    season_dfs.append(season_df)\n",
    "\n",
    "df = pd.concat(season_dfs, axis=0, sort=True)\n",
    "df = df.sort_values(by='Date')\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Complete, Partially Complete Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df[df.columns[~df.isnull().any()]]\n",
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_nulls = df[df.columns[df.isnull().any()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_with_nulls)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the data is missing based on the season\n",
    "# The Pinnacle closing odds data PSCA, PSCD, PSCH is missing for the first few seasons which is disappointing\n",
    "# But even with missing values, we will leave move this data onto the next stage\n",
    "# BbAH, BBAvAHA, BBAvAHH, BbMxAHA, and BbMXAHH have got more than 99% of their data \n",
    "# ie 3410/3420 = 0.997, so we will keep these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_threshold = 0.995\n",
    "# df.info().index\n",
    "# #droppers = ['BSA']\n",
    "df.dropna(thresh=df.shape[0]*0.6,how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_csv(INTERIM_DATA_DIR / league / save_file_name,\n",
    "                      parse_dates=['date'], index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first data file and take a look\n",
    "fp1 = form_fdcu_fps(RAW_DATA_DIR, source, nation, league, seasons)[0]\n",
    "fp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league = 'english-premier-league'\n",
    "GAME_DATA_DIR = RAW_DATA_DIR / 'football-data' / 'United-Kingdom' / league\n",
    "\n",
    "# seasons 2009-2010 through to 2017-2018\n",
    "start_year = 2009 ; end_year = 2018\n",
    "seasons = [str(year) + '-' + str(year+1) for year in range(start_year, end_year)]\n",
    "print(GAME_DATA_DIR)\n",
    "save_file_name = str('football-data-' + league + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Seasons into one file\n",
    "season_dfs=[]\n",
    "for season in seasons:\n",
    "    season_fp = GAME_DATA_DIR / season / 'football-data-co-uk' / 'season-data' / str(season + '.csv')\n",
    "#     season_dfs = pd.read_csv(season_fp)\n",
    "#     print(season_df.head())\n",
    "    season_df = pd.read_csv(season_fp, dayfirst=True, parse_dates=['Date'])\n",
    "    season_df['season'] = season\n",
    "    season_dfs.append(season_df)\n",
    "\n",
    "df = pd.concat(season_dfs, axis=0, sort=True)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df = df.copy(deep=True)\n",
    "\n",
    "# Drop unnecesary columns\n",
    "# Referee is not available for the full data set, and Half Time Result and Full Time Result can be calculated\n",
    "seasons_df.drop(columns=['Div', 'FTR', 'HTR', 'Referee', ], inplace=True)\n",
    "seasons_df.rename(columns={'Date': 'date', 'HomeTeam': 'h', 'AwayTeam': 'a',\n",
    "                          'FTHG': 'h_ftgoals', 'FTAG': 'a_ftgoals', 'HTHG': 'h_htgoals', 'HTAG': 'a_htgoals',\n",
    "                         'HS': 'h_shots', 'AS': 'a_shots', 'HST': 'h_sot', 'AST': 'a_sot',\n",
    "                         'HF': 'h_fouls', 'AF': 'a_fouls', 'HC': 'h_corners', 'AC': 'a_corners',\n",
    "                         'HY': 'h_ycards', 'AY': 'a_ycards', 'HR': 'h_rcards', 'AR': 'a_rcards'}, inplace=True)\n",
    "\n",
    "columns = {'B365H': 'odds_hwin_bet365', 'B365D': 'odds_draw_bet365', 'B365A': 'odds_awin_bet365',\n",
    "          'BWH': 'odds_hwin_BW', 'BWD': 'odds_draw_BW', 'BWA': 'odds_awin_BW',\n",
    "          'GBH': 'odds_hwin_GB', 'GBD': 'odds_draw_GB', 'GBA': 'odds_awin_GB',\n",
    "          'IWH': 'odds_hwin_IW', 'IWD': 'odds_draw_IW', 'IWA': 'odds_awin_IW',\n",
    "          'LBH': 'odds_hwin_LB', 'LBD': 'odds_draw_LB', 'LBA': 'odds_awin_LB',\n",
    "          'SBH': 'odds_hwin_SB', 'SBD': 'odds_draw_SB', 'SBA': 'odds_awin_SB',\n",
    "          'WHH': 'odds_hwin_WH', 'WHD': 'odds_draw_WH', 'WHA': 'odds_awin_WH',\n",
    "          'SJH': 'odds_hwin_SJ', 'SJD': 'odds_draw_SJ', 'SJA': 'odds_awin_SJ',\n",
    "          'VCH': 'odds_hwin_VC', 'VCD': 'odds_draw_VC', 'VCA': 'odds_awin_VC',           \n",
    "          'BSH': 'odds_hwin_BS', 'BSD': 'odds_draw_BS', 'BSA': 'odds_awin_BS',\n",
    "          'PSH': 'odds_hwin_pinn', 'PSD': 'odds_draw_pinn', 'PSA': 'odds_awin_pinn',\n",
    "           'Bb1X2': 'n_Bb1X2',\n",
    "           'BbMxH': 'odds_hwin_bbmax', 'BbMxD': 'odds_draw_bbmax', 'BbMxA': 'odds_awin_bbmax',\n",
    "           'BbAvH': 'odds_hwin_bbmean', 'BbAvD': 'odds_draw_bbmean', 'BbAvA': 'odds_awin_bbmean',\n",
    "           'BbOU': 'n_BbOU',\n",
    "           'BbMx>2.5': 'odds_ftgoalso2.5_bbmax', 'BbAv>2.5': 'odds_ftgoalso2.5_bbmean',\n",
    "           'BbMx<2.5': 'odds_ftgoalsu2.5_bbmax', 'BbAv<2.5': 'odds_ftgoalsu2.5_bbmean',\n",
    "           'BbAH': 'n_BbAsian',\n",
    "           'BbAHh': 'BbAsian_handicap',\n",
    "           'BbMxAHH': 'odds_asianhome_bbmax', 'BbAvAHH': 'odds_asianhome_bbmean',\n",
    "           'BbMxAHH': 'odds_asianhome_bbmax', 'BbAvAHH': 'odds_asianhome_bbmean',\n",
    "           'BbMxAHA': 'odds_asianaway_bbmax', 'BbAvAHH': 'odds_asianaway_bbmean',\n",
    "           'BbMxAHA': 'odds_asianaway_bbmax', 'BbAvAHA': 'odds_asianaway_bbmean',\n",
    "           'PSCH': 'clodds_hwin_pinn', 'PSCD': 'clodds_draw_pinn', 'PSCA': 'clodds_away_pinn'}\n",
    "seasons_df.rename(columns=columns, inplace=True)\n",
    "\n",
    "\n",
    "seasons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df.to_csv(INTERIM_DATA_DIR / league / save_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Back Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(INTERIM_DATA_DIR / league / save_file_name,\n",
    "                      parse_dates=['date'], index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
