{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Team Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "# add the 'src' directory to path to import modules\n",
    "src_dir = pathlib.Path().cwd().resolve().parent / 'src'\n",
    "#src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "# import my class code from the source\n",
    "# %aimport src-dir.filename\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "PROJECT_DIR = pathlib.Path.cwd().resolve().parent\n",
    "#DATA_DIR = PROJECT_DIR / 'data'\n",
    "#RAW_DATA_DIR = PROJECT_DIR / 'data' / '01-raw'\n",
    "CLEANED_DATA_DIR = PROJECT_DIR / 'data' / '03-cleaned'\n",
    "STDZED_DATA_DIR = PROJECT_DIR / 'data' / '04-standardized'\n",
    "REF_DATA_DIR = PROJECT_DIR / 'data' / 'reference'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select League Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Football- Data-co - uk\n",
    "\n",
    "+ Load standardize dictionary\n",
    "+ Use dictionary to form path to clean dataframes\n",
    "+ Load dataframes\n",
    "+ Standardize team names\n",
    "+ save to standardized directory"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epl_names_d = {'villa': 'aston-villa',\n",
    "              'blackburn': 'blackburn-rovers',\n",
    "              'birmingham': 'birmingham-city',\n",
    "              'bolton': 'bolton-wanderers',\n",
    "              'boro': 'middlesbrough',\n",
    "              'brighton': 'brighton-and-hove-albion',\n",
    "              'brighton-&-Hove Albion': ' brighton-and-hove-albion',\n",
    "              'cardiff': 'cardiff-city',\n",
    "              'huddersfield': 'huddersfield-town',\n",
    "              'hull': 'hull-city',\n",
    "              'leicester': 'leicester-city',\n",
    "              'leicester-cty': 'leicester-city',\n",
    "              'man-city': 'manchester-city',\n",
    "              'man-u': 'manchester-united',\n",
    "              'man-utd': 'manchester-united',\n",
    "              'manchester-utd': 'manchester-united',\n",
    "              'man-united': 'manchester-united',\n",
    "              'newcastle': 'newcastle-united',\n",
    "              'newcastle-utd': 'newcastle-united',\n",
    "              'norwich': 'norwich-city',\n",
    "              'qpr': 'queens-park-rangers',\n",
    "              'sheffield': 'sheffield-united',\n",
    "              'stoke': 'stoke-city',\n",
    "              'swansea': 'swansea-city',\n",
    "              'tottenham': 'tottenham-hotspur',\n",
    "              'west-brom': 'west-bromwich-albion',\n",
    "              'west-ham': 'west-ham-united',\n",
    "              'wigan': 'wigan-athletic',\n",
    "              'wolves': 'wolverhampton-wanderers'}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fp = REF_DATA_DIR / 'united-kingdom' / 'english-premier-league' / 'english-premier-league_std_name_dict.pkl'\n",
    "\n",
    "with open(fp, 'wb') as handle:\n",
    "    pickle.dump(epl_names_d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(fp, 'rb') as handle:\n",
    "    std_names_d = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "11\n",
      "3420 11\n",
      "3420 11\n"
     ]
    }
   ],
   "source": [
    "def get_fps(top_level_dir, ext='csv'):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    src_fps = list(top_level_dir.rglob('*.' + ext))\n",
    "    return src_fps\n",
    "\n",
    "def read_csvs(fps):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!\n",
    "    \"\"\"\n",
    "    dfs = [pd.read_csv(fp) for fp in fps]\n",
    "    return dfs\n",
    "\n",
    "def get_std_dict(df, std_dict_top_dir):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    nation = df['nation'].unique()[0]\n",
    "    league = df['league'].unique()[0]\n",
    "    fn = league + '.pkl'\n",
    "    fp = std_dict_top_dir / nation / league / fn\n",
    "    \n",
    "    try:\n",
    "        with open(fp, 'rb') as handle:\n",
    "            std_dict = pickle.load(handle)\n",
    "        return std_dict\n",
    "    except:\n",
    "        return {'key':'value'}\n",
    "    \n",
    "def get_std_dict_from_path(fp, std_dict_top_dir):\n",
    "    #'/media/david/5C14F53A14F517AA/code/ana_py37/projects/soccer-predictions/data/\n",
    "    #03-cleaned/whoscored-com-shotmaps/england/english-premier-league/2009-2010/Arsenal__Aston Villa.png')\n",
    "    fp_parts = str(fp).split('/')\n",
    "    nation = fp_parts[-4]\n",
    "    league = fp_parts[-3]\n",
    "    fn = league + '.pkl'\n",
    "    fp = std_dict_top_dir / nation / league / fn\n",
    "    # print(fp)\n",
    "    \n",
    "    try:\n",
    "        with open(fp, 'rb') as handle:\n",
    "            std_dict = pickle.load(handle)\n",
    "    except:\n",
    "        std_dict = {'key':'value'}\n",
    "    return std_dict\n",
    "\n",
    "def standardize_team_names(df_orig, std_names_dict):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    df = df_orig.copy(deep=True)\n",
    "    \n",
    "    # If there is no standard dictioanry available yet, return an empty dataframe\n",
    "    # so that we don't write a non-standardized dataframe to the standardized directory\n",
    "    if std_names_dict == {'key':'value'}:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        # Standardize the team names\n",
    "        df['h'] = df['h'].str.strip().str.lower().str.replace(' ', '-')\n",
    "        df.loc[df['h'].isin(std_names_dict.keys()), 'h'] = df['h'].map(std_names_dict)\n",
    "        df['a'] = df['a'].str.strip().str.lower().str.replace(' ', '-')\n",
    "        df.loc[df['a'].isin(std_names_dict.keys()), 'a'] = df['a'].map(std_names_dict)\n",
    "        if df['h'].isnull().sum() + df['a'].isnull().sum() > 0:\n",
    "            print(df.head(2))\n",
    "    return df\n",
    "\n",
    "def standardize_dfs(dfs, std_dict_top_dir):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    stdzed_dfs = []\n",
    "    for df in dfs:\n",
    "        std_dict = get_std_dict(df, std_dict_top_dir)\n",
    "        df = standardize_team_names(df, std_dict)\n",
    "        stdzed_dfs.append(df)\n",
    "    return stdzed_dfs\n",
    "\n",
    "\n",
    "def make_save_fps(top_level_dir, season_dfs, source = 'indatabet-com'):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    \n",
    "    scoped_fdcuk_fps = []\n",
    "    for season_df in season_dfs:\n",
    "        nation = season_df['nation'].unique()[0]\n",
    "        league = season_df['league'].unique()[0]\n",
    "        season = season_df['season'].unique()[0]\n",
    "        fn = str(season) + '.csv'\n",
    "        save_fp = top_level_dir / source / nation / league / season / fn\n",
    "        scoped_fdcuk_fps.append(save_fp)\n",
    "    return scoped_fdcuk_fps\n",
    "\n",
    "\n",
    "def save_dfs_to_fps(dfs, fps):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    for df, fp in zip(dfs, fps):\n",
    "        if not fp.exists():\n",
    "            fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(fp, index=False)\n",
    "        n += 1\n",
    "    return n\n",
    "\n",
    "\n",
    "def standardize_team_names_on_fp(fp, std_names_dict):\n",
    "#     dest_fps = []\n",
    "#     # Change to create parallel list, and then copy across with standard names\n",
    "#     ######################## !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! #########################3\n",
    "#     for heatmap_fp in heatmap_fps:\n",
    "        #print(heatmap_fp)\n",
    "    if std_names_dict == {'key': 'value'}:\n",
    "        fn = None\n",
    "    else:\n",
    "        h = str(fp).split('__')[0].split('/')[-1].lower().replace(' ', '-')\n",
    "        a = str(fp).split('__')[1].split('/')[0].split('.')[0].lower().replace(' ', '-')\n",
    "        if h in std_names_dict.keys():\n",
    "            h = std_names_dict[h]\n",
    "        if a in std_names_dict.keys():\n",
    "            a = std_names_dict[a]\n",
    "        fn = h + '__' + a + fp.suffix\n",
    "    return fn\n",
    "#         season = str(heatmap_fp.parent.parent).split('/')[-1]\n",
    "#         dest_fp_stub = pathlib.Path(str(heatmap_fp).replace('02-cleaned', '03-standardized')).parent\n",
    "#         # print(dest_fp_stub)\n",
    "#         fn = season + '__' + 'date' + '__' + h + '__' + a + heatmap_fp.suffix\n",
    "#         dest_fp = dest_fp_stub / fn\n",
    "#         #print(dest_fp)\n",
    "#         dest_fps.append(dest_fp)\n",
    "\n",
    "def standardize_fns(src_fps, std_dict_top_dir):\n",
    "    stdzed_fns = []\n",
    "    for fp in src_fps:\n",
    "        std_dict = get_std_dict_from_path(fp, std_dict_top_dir)\n",
    "        fn = standardize_team_names_on_fp(fp, std_dict)\n",
    "        stdzed_fns.append(fn)\n",
    "    return stdzed_fns\n",
    "    \n",
    "\n",
    "def standardize_fps(cleaned_src_fps, stdzed_fns, dest_top_dir, source_dir):\n",
    "    # '/media/david/5C14F53A14F517AA/code/ana_py37/projects/soccer-predictions/data/\n",
    "    # 03-cleaned/whoscored-com-shotmaps/england/english-premier-league/2009-2010/Arsenal__Aston Villa.png'\n",
    "    # stdzed_fn = 'arsenal__aston-villa.png'\n",
    "    stdzed_dest_fps = []\n",
    "    for cleaned_src_fp, stdzed_fn in zip(cleaned_src_fps, stdzed_fns):\n",
    "        if stdzed_fn == None:\n",
    "            stdzed_dest_fp = False\n",
    "        else:\n",
    "            fp_parts = str(cleaned_src_fp).split('/')\n",
    "            nation = fp_parts[-4]\n",
    "            league = fp_parts[-3]\n",
    "            season = fp_parts[-2]\n",
    "            stdzed_dest_fp = dest_top_dir / source_dir / nation / league / season / stdzed_fn\n",
    "            # print(fp)\n",
    "            # Compile dest file path\n",
    "        stdzed_dest_fps.append(stdzed_dest_fp)\n",
    "    return stdzed_dest_fps  \n",
    "    \n",
    "\n",
    "def copy_data(src_fps, dest_fps):\n",
    "    \"\"\"\n",
    "    Accepts a list of strings representing filepaths\n",
    "    Copies the files if they do not exist, otherwise counts if already there\n",
    "    Returns the number of files copied, and number of files already existing\n",
    "    \"\"\"\n",
    "    n_copied = 0\n",
    "    n_exist = 0\n",
    "    for src_fp, dest_fp in zip(src_fps, dest_fps):\n",
    "        if not dest_fp.exists():\n",
    "            dest_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "            # Copy the original files without touching them\n",
    "            dest_fp.write_bytes(src_fp.read_bytes())\n",
    "            n_copied += 1\n",
    "        else:\n",
    "            n_exist += 1\n",
    "    return n_copied, n_exist\n",
    "\n",
    "for source_dir in ['football-data-co-uk', 'indatabet-com']:\n",
    "    cleaned_fps = get_fps(CLEANED_DATA_DIR / source_dir, ext='csv')\n",
    "    dfs = read_csvs(cleaned_fps)\n",
    "    stdzed_dfs = standardize_dfs(dfs, REF_DATA_DIR)\n",
    "    # Not all standardized dictionaries available yet\n",
    "    stdzed_dfs = [df for df in stdzed_dfs if len(df) > 0]\n",
    "    stdzed_dfs_fps = make_save_fps(STDZED_DATA_DIR,\n",
    "                                    stdzed_dfs,\n",
    "                                    source = source_dir)\n",
    "    n_saved = save_dfs_to_fps(stdzed_dfs, stdzed_dfs_fps)\n",
    "    print(n_saved)\n",
    "    \n",
    "for source_dir in ['whoscored-com-heatmaps', 'whoscored-com-shotmaps']:\n",
    "    cleaned_src_fps = get_fps(CLEANED_DATA_DIR / source_dir, ext='png')\n",
    "    stdzed_fns = standardize_fns(cleaned_src_fps, REF_DATA_DIR)\n",
    "    stdzed_dest_fps = standardize_fps(cleaned_src_fps, stdzed_fns, STDZED_DATA_DIR, source_dir)\n",
    "    # Because not all the standardized dictionaries are available\n",
    "    # We only want to copy images that have actually been standardized\n",
    "    cleaned_src_fps = [src_fp for src_fp, dest_fp in zip(cleaned_src_fps, stdzed_dest_fps) if dest_fp != False]\n",
    "    stdzed_dest_fps = [dest_fp for src_fp, dest_fp in zip(cleaned_src_fps, stdzed_dest_fps) if dest_fp != False]\n",
    "    \n",
    "    #stdzed_dest_fps = fp for fp in stdzed_dest_fps if fp not None]\n",
    "    n_copied, n_exist = copy_data(cleaned_src_fps, stdzed_dest_fps)\n",
    "    print(n_copied, n_saved)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/david/5C14F53A14F517AA/code/ana_py37/projects/soccer-predictions/data/03-cleaned/whoscored-com-shotmaps/england/english-premier-league/2009-2010/Arsenal__Aston Villa.png')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_src_fps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arsenal__aston-villa.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdzed_fns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/david/5C14F53A14F517AA/code/ana_py37/projects/soccer-predictions/data/04-standardized/whoscored-com-shotmaps/england/english-premier-league/2009-2010/arsenal__aston-villa.png')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdzed_dest_fps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Dictionary to form path to cleaned dataframes dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nations = ['united-kingdom']\n",
    "leagues = ['english-premier-league']\n",
    "#sources = ['football-data-co-uk', 'indatabet-com', 'whoscored-com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_fdcu_fps(CLEANED_DATA_DIR, nation, league, seasons):\n",
    "    \"\"\"\n",
    "    Accepts directory names to enable reach into raw data directory\n",
    "    Returns full filepaths of the data files\n",
    "    This is different - different signature no source - to other versions - needs to be standardized\n",
    "    \"\"\"\n",
    "    fps = []\n",
    "    fdcu_specifics = ['football-data-co-uk', 'season-data']\n",
    "    for season in seasons:\n",
    "        fn = season + '.csv'\n",
    "        stub = CLEANED_DATA_DIR / fdcu_specifics[0] / nation / league / season\n",
    "        fp = stub / fn\n",
    "        #if fp.is_file():\n",
    "        if fp.exists():\n",
    "            fps.append(fp)\n",
    "    return fps\n",
    "\n",
    "fps = form_fdcu_fps(CLEANED_DATA_DIR, nations[0], leagues[0], seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fps = []\n",
    "for nation, league in zip(nations, leagues):\n",
    "    fps = form_fdcu_fps(CLEANED_DATA_DIR, nation, league, seasons)\n",
    "    all_fps.extend(fps)\n",
    "\n",
    "print(len(all_fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dfs = []\n",
    "for fp in all_fps:\n",
    "    season_df = pd.read_csv(fp, parse_dates=['date'], index_col=None)\n",
    "    season_dfs.append(season_df)\n",
    "season_dfs[-1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Team Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(src_fps, dest_fps):\n",
    "    \"\"\"\n",
    "    Accepts a list of strings representing filepaths\n",
    "    Copies the files if they do not exist, otherwise counts if already there\n",
    "    Returns the number of files copied, and number of files already existing\n",
    "    \"\"\"\n",
    "#     dest_fps = []\n",
    "#     for src_fp in src_fps:\n",
    "#         #dest_fps.append(src_fp.replace(str(env_dir), str(project_dir)))\n",
    "    n_copied = 0\n",
    "    n_exist = 0\n",
    "    for src_fp, dest_fp in zip(src_fps, dest_fps):\n",
    "#         src_fp = pathlib.Path(src_fp)\n",
    "#         dest_fp = pathlib.Path(dest_fp)\n",
    "        if not dest_fp.exists():\n",
    "            dest_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "            # Copy the original files without touching them\n",
    "            dest_fp.write_bytes(src_fp.read_bytes())\n",
    "            n_copied += 1\n",
    "        else:\n",
    "            n_exist += 1\n",
    "    return n_copied, n_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdze_names_to_dict(df_orig, std_names_d):\n",
    "    df = df_orig.copy(deep=True)\n",
    "    # Standardize the team names\n",
    "    df['h'] = df['h'].str.strip().str.lower().str.replace(' ', '-')\n",
    "    df.loc[df['h'].isin(std_names_d.keys()), 'h'] = df['h'].map(std_names_d)\n",
    "    df['a'] = df['a'].str.strip().str.lower().str.replace(' ', '-')\n",
    "    df.loc[df['a'].isin(std_names_d.keys()), 'a'] = df['a'].map(std_names_d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Standardized Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Change this to keep list of src and dest filepaths\n",
    "for df, src_fp in zip(season_dfs, all_fps):\n",
    "    new_df = stdze_names_to_dict(df, std_names_d)\n",
    "    # Write to new directory\n",
    "#     print(src_fp)\n",
    "    dest_fp = pathlib.Path(str(src_fp).replace('02-cleaned', '03-standardized'))\n",
    "#     print(dest_fp)\n",
    "    new_df.to_csv(dest_fp, index=None)\n",
    "    # copy_data([src_fp], [dest_fp])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Indatabet com\n",
    "\n",
    "+ Use dictionary to form path to clean dataframes\n",
    "+ Load dataframes\n",
    "+ Standardize team names\n",
    "+ save to standardized directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_indatabet_fps(CLEANED_DATA_DIR, nation, league, seasons):\n",
    "    \"\"\"\n",
    "    Accepts directory names to enable reach into raw data directory\n",
    "    Returns full filepaths of the data files\n",
    "    This is different - different signature no source - to other versions - needs to be standardized\n",
    "    \"\"\"\n",
    "    fps = []\n",
    "    indatabet_specifics = ['indatabet-com', 'season-data']\n",
    "    for season in seasons:\n",
    "        fn = season + '.csv'\n",
    "        stub = CLEANED_DATA_DIR / indatabet_specifics[0] / nation / league / season\n",
    "        fp = stub / fn\n",
    "        #if fp.is_file():\n",
    "        if fp.exists():\n",
    "            fps.append(fp)\n",
    "    return fps\n",
    "\n",
    "fps = form_indatabet_fps(CLEANED_DATA_DIR, nations[0], leagues[0], seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fps = []\n",
    "for nation, league in zip(nations, leagues):\n",
    "    fps = form_indatabet_fps(CLEANED_DATA_DIR, nation, league, seasons)\n",
    "    all_fps.extend(fps)\n",
    "\n",
    "print(len(all_fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dfs = []\n",
    "for fp in all_fps:\n",
    "    season_df = pd.read_csv(fp, parse_dates=['date'], index_col=None)\n",
    "    season_dfs.append(season_df)\n",
    "season_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdze_names_to_dict(df_orig, std_names_d):\n",
    "    df = df_orig.copy(deep=True)\n",
    "    # Standardize the team names\n",
    "    df['h'] = df['h'].str.strip().str.lower().str.replace(' ', '-')\n",
    "    df.loc[df['h'].isin(std_names_d.keys()), 'h'] = df['h'].map(std_names_d)\n",
    "    df['a'] = df['a'].str.strip().str.lower().str.replace(' ', '-')\n",
    "    df.loc[df['a'].isin(std_names_d.keys()), 'a'] = df['a'].map(std_names_d)\n",
    "#     print(sorted(df['h'].unique()))\n",
    "#     print(sorted(df['a'].unique()))\n",
    "#     print('\\n\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this to keep list of src and dest filepaths\n",
    "for df, src_fp in zip(season_dfs, all_fps):\n",
    "    new_df = stdze_names_to_dict(df, std_names_d)\n",
    "    # Write to new directory\n",
    "#     print(src_fp)\n",
    "    dest_fp = pathlib.Path(str(src_fp).replace('02-cleaned', '03-standardized'))\n",
    "#     print(dest_fp)\n",
    "    # copy_data([src_fp], [dest_fp])\n",
    "    new_df.to_csv(dest_fp, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Whoscored com\n",
    "\n",
    "+ Use dictionary to form path to clean images\n",
    "+ Load image filepaths\n",
    "+ Standardize team names\n",
    "+ save to standardized directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nation = 'united-kingdom'\n",
    "league = 'english-premier-league'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_fps = []\n",
    "heatmap_dirs = [d for d in pathlib.Path(CLEANED_DATA_DIR /'whoscored-com' / nation / league).rglob('**/*')\n",
    "               if d.is_dir() and str(d).split('/')[-1] =='heatmaps']\n",
    "for heatmap_dir in heatmap_dirs:\n",
    "    heatmaps = [fp for fp in heatmap_dir.iterdir() if fp.is_file()]\n",
    "    heatmap_fps.extend(heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_fps[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heatmap_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shotmap_fps = []\n",
    "shotmap_dirs = [d for d in pathlib.Path(CLEANED_DATA_DIR /'whoscored-com'/ nation / league).rglob('**/*')\n",
    "               if d.is_dir() and str(d).split('/')[-1] =='shotmaps']\n",
    "for shotmap_dir in shotmap_dirs:\n",
    "    shotmaps = [fp for fp in shotmap_dir.iterdir() if fp.is_file()]\n",
    "    shotmap_fps.extend(shotmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shotmap_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_fps = []\n",
    "# Change to create parallel list, and then copy across with standard names\n",
    "######################## !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! #########################3\n",
    "for heatmap_fp in heatmap_fps:\n",
    "    #print(heatmap_fp)\n",
    "    h = str(heatmap_fp).split('__')[0].split('/')[-1].lower().replace(' ', '-')\n",
    "    a = str(heatmap_fp).split('__')[1].split('/')[0].split('.')[0].lower().replace(' ', '-')\n",
    "    if h in std_names_d.keys():\n",
    "        h = std_names_d[h]\n",
    "    if a in std_names_d.keys():\n",
    "        a = std_names_d[a]\n",
    "    season = str(heatmap_fp.parent.parent).split('/')[-1]\n",
    "    dest_fp_stub = pathlib.Path(str(heatmap_fp).replace('02-cleaned', '03-standardized')).parent\n",
    "    # print(dest_fp_stub)\n",
    "    fn = season + '__' + 'date' + '__' + h + '__' + a + heatmap_fp.suffix\n",
    "    dest_fp = dest_fp_stub / fn\n",
    "    #print(dest_fp)\n",
    "    dest_fps.append(dest_fp)\n",
    "    #break\n",
    "#     fps[season + '__' + 'date' + '__' + h + '__' + a] = heatmap_fp\n",
    "# for k in list(fps.keys())[0:5]:\n",
    "#     print(f'{k} : {fps[k]}')\n",
    "#print(fps.items()[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_copied, n_exist= copy_data(heatmap_fps, dest_fps)\n",
    "print(n_copied, n_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_sm_fps = []\n",
    "for shotmap_fp in shotmap_fps:\n",
    "#     print(heatmap_fp)\n",
    "    h = str(shotmap_fp).split('__')[0].split('/')[-1].lower().replace(' ', '-')\n",
    "    a = str(shotmap_fp).split('__')[1].split('/')[0].split('.')[0].lower().replace(' ', '-')\n",
    "    if h in std_names_d.keys():\n",
    "        h = std_names_d[h]\n",
    "    if a in std_names_d.keys():\n",
    "        a = std_names_d[a]\n",
    "    season = str(shotmap_fp.parent.parent).split('/')[-1] \n",
    "    dest_sm_fp_stub = pathlib.Path(str(shotmap_fp).replace('02-cleaned', '03-standardized')).parent\n",
    "    # print(dest_fp_stub)\n",
    "    fn = season + '__' + 'date' + '__' + h + '__' + a + shotmap_fp.suffix\n",
    "    dst_sm_fp = dest_sm_fp_stub / fn\n",
    "    #print(dest_fp)\n",
    "    dst_sm_fps.append(dst_sm_fp)\n",
    "\n",
    "#     # Take a peek at the original shotmap filepaths \n",
    "# for k in list(fpss.keys())[0:5]:\n",
    "#     print(f'{k} : {fpss[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_copied, n_exist= copy_data(shotmap_fps, dst_sm_fps)\n",
    "print(n_copied, n_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hm_src_fps = [] ; hm_dest_fps = []\n",
    "sm_src_fps = [] ; sm_dest_fps = []\n",
    "for nation, league in zip(nations, leagues):\n",
    "    print(nation, league)\n",
    "    for season in seasons:\n",
    "        src_stub = RAW_DATA_DIR / 'football-data' / nation / league / season / 'who-scored-com'\n",
    "        dest_stub = CLEANED_DATA_DIR / 'whoscored-com' / nation / league / season \n",
    "#         print(stub)\n",
    "        hm_src_dir = src_stub / 'game-heatmaps'\n",
    "        sm_src_dir = src_stub / 'game-shotmaps'\n",
    "        if hm_src_dir.exists() and len(list(hm_src_dir.glob('*.png'))) > 0:\n",
    "            hm_src_fps_sublist = list(hm_src_dir.glob('*.png'))\n",
    "            hm_src_fps.append(hm_src_fps_sublist)\n",
    "            hm_src_fps.append(list(hm_src_dir.glob('*.png')))\n",
    "            #print(hm_src_fps[0:3], '\\n')\n",
    "            hm_dest_fps.append([dest_stub / 'heatmaps' / fp.name for fp in hm_src_fps_sublist])\n",
    "            \n",
    "        if sm_src_dir.exists() and len(list(sm_src_dir.glob('*.png'))) > 0:\n",
    "            sm_src_fps_sublist = list(sm_src_dir.glob('*.png'))\n",
    "            sm_src_fps.append(sm_src_fps_sublist)\n",
    "            sm_src_fps.append(list(sm_src_dir.glob('*.png')))\n",
    "            #print(hm_src_fps[0:3], '\\n')\n",
    "            sm_dest_fps.append([dest_stub / 'shotmaps' / fp.name for fp in sm_src_fps_sublist])\n",
    "        \n",
    "# hm_dest_fps[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(src_fps, dest_fps):\n",
    "    \"\"\"\n",
    "    Accepts a list of strings representing filepaths\n",
    "    Copies the files if they do not exist, otherwise counts if already there\n",
    "    Returns the number of files copied, and number of files already existing\n",
    "    \"\"\"\n",
    "#     dest_fps = []\n",
    "#     for src_fp in src_fps:\n",
    "#         #dest_fps.append(src_fp.replace(str(env_dir), str(project_dir)))\n",
    "    n_copied = 0\n",
    "    n_exist = 0\n",
    "    for src_fp, dest_fp in zip(src_fps, dest_fps):\n",
    "#         src_fp = pathlib.Path(src_fp)\n",
    "#         dest_fp = pathlib.Path(dest_fp)\n",
    "        if not dest_fp.exists():\n",
    "            dest_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "            # Copy the original files without touching them\n",
    "            dest_fp.write_bytes(src_fp.read_bytes())\n",
    "            n_copied += 1\n",
    "        else:\n",
    "            n_exist += 1\n",
    "    return n_copied, n_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_src_flatlist = [item for sublist in hm_src_fps for item in sublist]\n",
    "hm_dest_flatlist = [item for sublist in hm_dest_fps for item in sublist]\n",
    "n_copied, n_exist = copy_data(hm_src_flatlist, hm_dest_flatlist)\n",
    "print(n_copied, n_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_src_flatlist = [item for sublist in sm_src_fps for item in sublist]\n",
    "sm_dest_flatlist = [item for sublist in sm_dest_fps for item in sublist]\n",
    "n_copied, n_exist = copy_data(sm_src_flatlist, sm_dest_flatlist)\n",
    "print(n_copied, n_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy(deep=True)\n",
    "\n",
    "def copy_src_to_dest(src_fp, dest_fp):\n",
    "    if not dest_fp.exists():\n",
    "        dest_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # Copy the original files without touching them\n",
    "        dest_fp.write_bytes(src_fp.read_bytes())\n",
    "\n",
    "def form_image_fp(row, league=None, image_type=None):\n",
    "    row = row.copy(deep=True)\n",
    "    season = row.name[0]\n",
    "    date = str(row.name[1].date())\n",
    "    h = row['h']\n",
    "    a = row['a']\n",
    "    key = season + '__' + 'date' + '__' + h + '__' + a\n",
    "    src_fp = fps[key]\n",
    "    ext = src_fp.suffix\n",
    "    dest_fp = INTERIM_DATA_DIR / league/ 'heatmaps' / str(key.replace('date', date) + src_fp.suffix) \n",
    "    # copy_src_to_dest(src_fp, dest_fp)\n",
    "    rel_path = str(dest_fp).replace(str(PROJECT_DIR), '')\n",
    "    return rel_path\n",
    "    \n",
    "df1.loc[:, 'heatmap_path'] = df1.apply(form_image_fp,\n",
    "                                       league=league,\n",
    "                                       image_type='heatmaps', axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league = 'english-premier-league'\n",
    "fn = str('football-data-' + league + '.csv')\n",
    "df = pd.read_csv(INTERIM_DATA_DIR / league / fn, parse_dates=['date'], index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_name =  str('merge-1-' + league + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Team Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epl_names_d = {'villa': 'aston-villa',\n",
    "              'blackburn': 'blackburn-rovers',\n",
    "              'birmingham': 'birmingham-city',\n",
    "              'bolton': 'bolton-wanderers',\n",
    "              'brighton': 'brighton-and-hove-albion',\n",
    "              'brighton-&-Hove Albion': ' brighton-and-hove-albion',\n",
    "              'cardiff': 'cardiff-city',\n",
    "              'huddersfield': 'huddersfield-town',\n",
    "              'hull': 'hull-city',\n",
    "              'leicester': 'leicester-city',\n",
    "              'leicester-cty': 'leicester-city',\n",
    "              'man-city': 'manchester-city',\n",
    "              'man-u': 'manchester-united',\n",
    "              'man-utd': 'manchester-united',\n",
    "              'manchester-utd': 'manchester-united',\n",
    "              'man-united': 'manchester-united',\n",
    "              'boro': 'middlesborough',\n",
    "              'newcastle': 'newcastle-united',\n",
    "              'newcastle-utd': 'newcastle-united',\n",
    "              'norwich': 'norwich-city',\n",
    "              'qpr': 'queens-park-rangers',\n",
    "              'stoke': 'stoke-city',\n",
    "              'swansea': 'swansea-city',\n",
    "              'tottenham': 'tottenham-hotspur',\n",
    "              'west-brom': 'west-bromwich-albion',\n",
    "              'west-ham': 'west-ham-united',\n",
    "              'wigan': 'wigan-athletic',\n",
    "              'wolves': 'wolverhampton-wanderers'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'english-premier-league_std_name_dict.pkl'\n",
    "\n",
    "with open(REF_DATA_DIR / fn, 'wb') as handle:\n",
    "    pickle.dump(epl_names_d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(REF_DATA_DIR / fn, 'rb') as handle:\n",
    "    std_names_d = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the team names\n",
    "df['h'] = df['h'].str.strip().str.lower().str.replace(' ', '-')\n",
    "df.loc[df['h'].isin(std_names_d.keys()), 'h'] = df['h'].map(std_names_d)\n",
    "df['a'] = df['a'].str.strip().str.lower().str.replace(' ', '-')\n",
    "df.loc[df['a'].isin(std_names_d.keys()), 'a'] = df['a'].map(std_names_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['season', 'date'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Name and Copy Heatmaps and Shotmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'england'\n",
    "league_dir = 'premier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heatmap_fps = []\n",
    "heatmap_dirs = [d for d in pathlib.Path(RAW_DATA_DIR /'soccer' / country / league_dir).rglob('**/*')\n",
    "               if d.is_dir() and str(d).split('/')[-1] =='heatmaps']\n",
    "for heatmap_dir in heatmap_dirs:\n",
    "    heatmaps = [fp for fp in heatmap_dir.iterdir() if fp.is_file()]\n",
    "    heatmap_fps.extend(heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shotmap_fps = []\n",
    "shotmap_dirs = [d for d in pathlib.Path(RAW_DATA_DIR /'soccer'/ country / league_dir).rglob('**/*')\n",
    "               if d.is_dir() and str(d).split('/')[-1] =='shotmaps']\n",
    "for shotmap_dir in shotmap_dirs:\n",
    "    shotmaps = [fp for fp in shotmap_dir.iterdir() if fp.is_file()]\n",
    "    shotmap_fps.extend(shotmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = {}\n",
    "for heatmap_fp in heatmap_fps:\n",
    "#     print(heatmap_fp)\n",
    "    h = str(heatmap_fp).split('__')[0].split('/')[-1].lower().replace(' ', '-')\n",
    "    a = str(heatmap_fp).split('__')[1].split('/')[0].split('.')[0].lower().replace(' ', '-')\n",
    "    if h in std_names_d.keys():\n",
    "        h = std_names_d[h]\n",
    "    if a in std_names_d.keys():\n",
    "        a = std_names_d[a]\n",
    "    season = str(heatmap_fp.parent.parent).split('/')[-1] \n",
    "    fps[season + '__' + 'date' + '__' + h + '__' + a] = heatmap_fp\n",
    "for k in list(fps.keys())[0:5]:\n",
    "    print(f'{k} : {fps[k]}')\n",
    "#print(fps.items()[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpss = {}\n",
    "for shotmap_fp in shotmap_fps:\n",
    "#     print(heatmap_fp)\n",
    "    h = str(shotmap_fp).split('__')[0].split('/')[-1].lower().replace(' ', '-')\n",
    "    a = str(shotmap_fp).split('__')[1].split('/')[0].split('.')[0].lower().replace(' ', '-')\n",
    "    if h in std_names_d.keys():\n",
    "        h = std_names_d[h]\n",
    "    if a in std_names_d.keys():\n",
    "        a = std_names_d[a]\n",
    "    season = str(shotmap_fp.parent.parent).split('/')[-1] \n",
    "    fpss[season + '__' + 'date' + '__' + h + '__' + a] = shotmap_fp\n",
    "\n",
    "    # Take a peek at the original shotmap filepaths \n",
    "for k in list(fpss.keys())[0:5]:\n",
    "    print(f'{k} : {fpss[k]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge - Get Image Paths into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy(deep=True)\n",
    "\n",
    "def copy_src_to_dest(src_fp, dest_fp):\n",
    "    if not dest_fp.exists():\n",
    "        dest_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # Copy the original files without touching them\n",
    "        dest_fp.write_bytes(src_fp.read_bytes())\n",
    "\n",
    "def form_image_fp(row, league=None, image_type=None):\n",
    "    row = row.copy(deep=True)\n",
    "    season = row.name[0]\n",
    "    date = str(row.name[1].date())\n",
    "    h = row['h']\n",
    "    a = row['a']\n",
    "    key = season + '__' + 'date' + '__' + h + '__' + a\n",
    "    src_fp = fps[key]\n",
    "    ext = src_fp.suffix\n",
    "    dest_fp = INTERIM_DATA_DIR / league/ 'heatmaps' / str(key.replace('date', date) + src_fp.suffix) \n",
    "    copy_src_to_dest(src_fp, dest_fp)\n",
    "    rel_path = str(dest_fp).replace(str(PROJECT_DIR), '')\n",
    "    return rel_path\n",
    "    \n",
    "df1.loc[:, 'heatmap_path'] = df1.apply(form_image_fp,\n",
    "                                       league=league,\n",
    "                                       image_type='heatmaps', axis=1)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_image_fp(row, league=None, image_type=None):\n",
    "    row = row.copy(deep=True)\n",
    "    season = row.name[0]\n",
    "    date = str(row.name[1].date())\n",
    "    h = row['h']\n",
    "    a = row['a']\n",
    "    key = season + '__' + 'date' + '__' + h + '__' + a\n",
    "    src_fp = fpss[key]\n",
    "    ext = src_fp.suffix\n",
    "    dest_fp = INTERIM_DATA_DIR / league/ 'shotmaps' / str(key.replace('date', date) + src_fp.suffix) \n",
    "    copy_src_to_dest(src_fp, dest_fp)\n",
    "    rel_path = str(dest_fp).replace(str(PROJECT_DIR), '')\n",
    "    return rel_path\n",
    "    \n",
    "df1.loc[:, 'shotmap_path'] = df1.apply(form_image_fp,\n",
    "                                       league=league,\n",
    "                                       image_type='shotmaps', axis=1)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[0].loc['heatmap_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[0].loc['shotmap_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(INTERIM_DATA_DIR / league / save_file_name, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tidy up code - leave image paths as relative to project dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
