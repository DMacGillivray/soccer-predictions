{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Team Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "# add the 'src' directory to path to import modules\n",
    "src_dir = pathlib.Path().cwd().resolve().parent / 'src'\n",
    "#src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "# import my class code from the source\n",
    "# %aimport src-dir.filename\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "PROJECT_DIR = pathlib.Path.cwd().resolve().parent\n",
    "STDZED_DATA_DIR = PROJECT_DIR / 'data' / '04-standardized'\n",
    "MERGED_DATA_DIR = PROJECT_DIR / 'data' / '05-merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "def get_fps(top_level_dir, ext='csv'):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    src_fps = list(top_level_dir.rglob('*.' + ext))\n",
    "    return src_fps\n",
    "\n",
    "def read_csvs(fps):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!\n",
    "    \"\"\"\n",
    "    dfs = [pd.read_csv(fp) for fp in fps]\n",
    "    return dfs\n",
    "\n",
    "def get_std_dict(df, std_dict_top_dir):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    nation = df['nation'].unique()[0]\n",
    "    league = df['league'].unique()[0]\n",
    "    fn = league + '.pkl'\n",
    "    fp = std_dict_top_dir / nation / league / fn\n",
    "    \n",
    "    try:\n",
    "        with open(fp, 'rb') as handle:\n",
    "            std_dict = pickle.load(handle)\n",
    "        return std_dict\n",
    "    except:\n",
    "        return {'key':'value'}\n",
    "    \n",
    "def get_std_dict_from_path(fp, std_dict_top_dir):\n",
    "    #'/media/david/5C14F53A14F517AA/code/ana_py37/projects/soccer-predictions/data/\n",
    "    #03-cleaned/whoscored-com-shotmaps/england/english-premier-league/2009-2010/Arsenal__Aston Villa.png')\n",
    "    fp_parts = str(fp).split('/')\n",
    "    nation = fp_parts[-4]\n",
    "    league = fp_parts[-3]\n",
    "    fn = league + '.pkl'\n",
    "    fp = std_dict_top_dir / nation / league / fn\n",
    "    # print(fp)\n",
    "    \n",
    "    try:\n",
    "        with open(fp, 'rb') as handle:\n",
    "            std_dict = pickle.load(handle)\n",
    "    except:\n",
    "        std_dict = {'key':'value'}\n",
    "    return std_dict\n",
    "\n",
    "def standardize_team_names(df_orig, std_names_dict):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    df = df_orig.copy(deep=True)\n",
    "    \n",
    "    # If there is no standard dictioanry available yet, return an empty dataframe\n",
    "    # so that we don't write a non-standardized dataframe to the standardized directory\n",
    "    if std_names_dict == {'key':'value'}:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        # Standardize the team names\n",
    "        df['h'] = df['h'].str.strip().str.lower().str.replace(' ', '-')\n",
    "        df.loc[df['h'].isin(std_names_dict.keys()), 'h'] = df['h'].map(std_names_dict)\n",
    "        df['a'] = df['a'].str.strip().str.lower().str.replace(' ', '-')\n",
    "        df.loc[df['a'].isin(std_names_dict.keys()), 'a'] = df['a'].map(std_names_dict)\n",
    "        if df['h'].isnull().sum() + df['a'].isnull().sum() > 0:\n",
    "            print(df.head(2))\n",
    "    return df\n",
    "\n",
    "def standardize_dfs(dfs, std_dict_top_dir):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    stdzed_dfs = []\n",
    "    for df in dfs:\n",
    "        std_dict = get_std_dict(df, std_dict_top_dir)\n",
    "        df = standardize_team_names(df, std_dict)\n",
    "        stdzed_dfs.append(df)\n",
    "    return stdzed_dfs\n",
    "\n",
    "\n",
    "def make_save_fps(top_level_dir, season_dfs, source = 'indatabet-com'):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    \n",
    "    scoped_fdcuk_fps = []\n",
    "    for season_df in season_dfs:\n",
    "        nation = season_df['nation'].unique()[0]\n",
    "        league = season_df['league'].unique()[0]\n",
    "        season = season_df['season'].unique()[0]\n",
    "        fn = str(season) + '.csv'\n",
    "        save_fp = top_level_dir / source / nation / league / season / fn\n",
    "        scoped_fdcuk_fps.append(save_fp)\n",
    "    return scoped_fdcuk_fps\n",
    "\n",
    "\n",
    "def save_dfs_to_fps(dfs, fps):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    for df, fp in zip(dfs, fps):\n",
    "        if not fp.exists():\n",
    "            fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(fp, index=False)\n",
    "        n += 1\n",
    "    return n\n",
    "\n",
    "\n",
    "def standardize_team_names_on_fp(fp, std_names_dict):\n",
    "    if std_names_dict == {'key': 'value'}:\n",
    "        fn = None\n",
    "    else:\n",
    "        h = str(fp).split('__')[0].split('/')[-1].lower().replace(' ', '-')\n",
    "        a = str(fp).split('__')[1].split('/')[0].split('.')[0].lower().replace(' ', '-')\n",
    "        if h in std_names_dict.keys():\n",
    "            h = std_names_dict[h]\n",
    "        if a in std_names_dict.keys():\n",
    "            a = std_names_dict[a]\n",
    "        fn = h + '__' + a + fp.suffix\n",
    "    return fn\n",
    "\n",
    "\n",
    "def standardize_fns(src_fps, std_dict_top_dir):\n",
    "    stdzed_fns = []\n",
    "    for fp in src_fps:\n",
    "        std_dict = get_std_dict_from_path(fp, std_dict_top_dir)\n",
    "        fn = standardize_team_names_on_fp(fp, std_dict)\n",
    "        stdzed_fns.append(fn)\n",
    "    return stdzed_fns\n",
    "    \n",
    "\n",
    "def standardize_fps(cleaned_src_fps, stdzed_fns, dest_top_dir, source_dir):\n",
    "    # '/media/david/5C14F53A14F517AA/code/ana_py37/projects/soccer-predictions/data/\n",
    "    # 03-cleaned/whoscored-com-shotmaps/england/english-premier-league/2009-2010/Arsenal__Aston Villa.png'\n",
    "    # stdzed_fn = 'arsenal__aston-villa.png'\n",
    "    stdzed_dest_fps = []\n",
    "    for cleaned_src_fp, stdzed_fn in zip(cleaned_src_fps, stdzed_fns):\n",
    "        if stdzed_fn == None:\n",
    "            stdzed_dest_fp = False\n",
    "        else:\n",
    "            fp_parts = str(cleaned_src_fp).split('/')\n",
    "            nation = fp_parts[-4]\n",
    "            league = fp_parts[-3]\n",
    "            season = fp_parts[-2]\n",
    "            stdzed_dest_fp = dest_top_dir / source_dir / nation / league / season / stdzed_fn\n",
    "            # print(fp)\n",
    "            # Compile dest file path\n",
    "        stdzed_dest_fps.append(stdzed_dest_fp)\n",
    "    return stdzed_dest_fps  \n",
    "    \n",
    "\n",
    "def copy_data(src_fps, dest_fps):\n",
    "    \"\"\"\n",
    "    Accepts a list of strings representing filepaths\n",
    "    Copies the files if they do not exist, otherwise counts if already there\n",
    "    Returns the number of files copied, and number of files already existing\n",
    "    \"\"\"\n",
    "    n_copied = 0\n",
    "    n_exist = 0\n",
    "    for src_fp, dest_fp in zip(src_fps, dest_fps):\n",
    "        if not dest_fp.exists():\n",
    "            dest_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "            # Copy the original files without touching them\n",
    "            dest_fp.write_bytes(src_fp.read_bytes())\n",
    "            n_copied += 1\n",
    "        else:\n",
    "            n_exist += 1\n",
    "    return n_copied, n_exist\n",
    "\n",
    "def merger(football_df, odds_df2):\n",
    "    #dfs = sorted(list(df_dict.values()), key=lambda x: len(x), reverse=True)\n",
    "    # merge_asof on date using home team, awat_team, home_goals, and away_goals to match\n",
    "    # merge_asof does a left join, so put longest daf on left, so get max data into merged\n",
    "    merged = pd.merge_asof(football_df, odds_df2,\n",
    "                           on='date',\n",
    "                           by=['h', 'a', 'h_ftGoals', 'a_ftGoals'],\n",
    "                           suffixes=('_ic', '_fdcu'),\n",
    "                           tolerance=pd.Timedelta(days=2),\n",
    "                           direction='nearest'\n",
    "                           )\n",
    "    # # Put a date difference column into the merged df\n",
    "    # merged['dates_diff'] = merged['date_ic'] - merged['date_fdcu']\n",
    "    # # Write the merge issues data to a yaml file\n",
    "\n",
    "    merged.sort_values(by='date', ascending=True, inplace=True)\n",
    "    return merged\n",
    "\n",
    "\n",
    "def do_merge(left_dfs, right_dfs):\n",
    "    merged_dfs = []\n",
    "    for left_df, right_df in zip(left_dfs, right_dfs):\n",
    "\n",
    "        # cast to float to enable a join cannot join on integer and float\n",
    "        # This should move into Clean \n",
    "        left_df['date'] = pd.to_datetime(left_df['date'])\n",
    "        right_df['date'] = pd.to_datetime(right_df['date'])\n",
    "        \n",
    "        cols = ['h_ftGoals', 'a_ftGoals']\n",
    "        left_df[cols] = left_df[cols].apply(pd.to_numeric, errors='coerce', downcast='float', axis=1)\n",
    "        right_df[cols] = right_df[cols].apply(pd.to_numeric, errors='coerce', downcast='float', axis=1)\n",
    "        \n",
    "        try:\n",
    "            merged_df = pd.merge_asof(left_df, right_df,\n",
    "                                   on='date',\n",
    "                                   by = ['h', 'a', 'h_ftGoals', 'a_ftGoals',\n",
    "                                         'nation', 'league', 'season', 'result'],\n",
    "                                   suffixes=('_ic', '_fdcu'),\n",
    "                                   tolerance=pd.Timedelta(days=2),\n",
    "                                   direction='nearest')\n",
    "            merged_df.sort_values(by='date', ascending=True, inplace=True)\n",
    "            merged_dfs.append(merged_df)\n",
    "        except:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "    return merged_dfs\n",
    "\n",
    "\n",
    "def get_matching_fps(left_df_fps, right_df_fps, left_source, right_source):\n",
    "    left_fps = [fp for fp in left_df_fps if pathlib.Path(str(fp).replace(left_source, right_source)) in right_df_fps]\n",
    "    right_fps =[fp for fp in right_df_fps if pathlib.Path(str(fp).replace(left_source, right_source)) in right_df_fps]\n",
    "    return left_fps, right_fps\n",
    "    \n",
    "    \n",
    "def make_save_fps(top_level_dir, season_dfs, source = 'indatabet-com'):\n",
    "    \"\"\"\n",
    "    COMMON !!!!!!!!!!!!\n",
    "    \"\"\"\n",
    "    \n",
    "    scoped_fdcuk_fps = []\n",
    "    for season_df in season_dfs:\n",
    "        nation = season_df['nation'].unique()[0]\n",
    "        league = season_df['league'].unique()[0]\n",
    "        season = season_df['season'].unique()[0]\n",
    "        fn = str(season) + '.csv'\n",
    "        save_fp = top_level_dir / source / nation / league / season / fn\n",
    "        scoped_fdcuk_fps.append(save_fp)\n",
    "    return scoped_fdcuk_fps   \n",
    "\n",
    "left_source = 'football-data-co-uk'\n",
    "right_source = 'indatabet-com'\n",
    "left_df_fps = get_fps(STDZED_DATA_DIR / left_source, ext='csv')\n",
    "right_df_fps = get_fps(STDZED_DATA_DIR / right_source, ext='csv')\n",
    "left_df_fps, right_df_fps = get_matching_fps(left_df_fps, right_df_fps, left_source, right_source)\n",
    "left_dfs = read_csvs(left_df_fps)\n",
    "right_dfs = read_csvs(right_df_fps)\n",
    "merged_dfs = do_merge(left_dfs, right_dfs)\n",
    "#merged_dfs[0].head()\n",
    "\n",
    "# NEXT NEXT NEXT NEXT NEXT !!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!! \n",
    "merged_fps = make_save_fps(MERGED_DATA_DIR, merged_dfs, source= '')\n",
    "n_saved = save_dfs_to_fps(merged_dfs, merged_fps)\n",
    "print(n_saved)\n",
    "# NEXT NEXT NEXT NEXT NEXT !!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!! \n",
    "# INCORORATE IMAGES into DATAFRAMR - original code below\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge - Get Image Paths into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy(deep=True)\n",
    "\n",
    "def copy_src_to_dest(src_fp, dest_fp):\n",
    "    if not dest_fp.exists():\n",
    "        dest_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # Copy the original files without touching them\n",
    "        dest_fp.write_bytes(src_fp.read_bytes())\n",
    "\n",
    "def form_image_fp(row, league=None, image_type=None):\n",
    "    row = row.copy(deep=True)\n",
    "    season = row.name[0]\n",
    "    date = str(row.name[1].date())\n",
    "    h = row['h']\n",
    "    a = row['a']\n",
    "    key = season + '__' + 'date' + '__' + h + '__' + a\n",
    "    src_fp = fps[key]\n",
    "    ext = src_fp.suffix\n",
    "    dest_fp = INTERIM_DATA_DIR / league/ 'heatmaps' / str(key.replace('date', date) + src_fp.suffix) \n",
    "    copy_src_to_dest(src_fp, dest_fp)\n",
    "    rel_path = str(dest_fp).replace(str(PROJECT_DIR), '')\n",
    "    return rel_path\n",
    "    \n",
    "df1.loc[:, 'heatmap_path'] = df1.apply(form_image_fp,\n",
    "                                       league=league,\n",
    "                                       image_type='heatmaps', axis=1)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_image_fp(row, league=None, image_type=None):\n",
    "    row = row.copy(deep=True)\n",
    "    season = row.name[0]\n",
    "    date = str(row.name[1].date())\n",
    "    h = row['h']\n",
    "    a = row['a']\n",
    "    key = season + '__' + 'date' + '__' + h + '__' + a\n",
    "    src_fp = fpss[key]\n",
    "    ext = src_fp.suffix\n",
    "    dest_fp = INTERIM_DATA_DIR / league/ 'shotmaps' / str(key.replace('date', date) + src_fp.suffix) \n",
    "    copy_src_to_dest(src_fp, dest_fp)\n",
    "    rel_path = str(dest_fp).replace(str(PROJECT_DIR), '')\n",
    "    return rel_path\n",
    "    \n",
    "df1.loc[:, 'shotmap_path'] = df1.apply(form_image_fp,\n",
    "                                       league=league,\n",
    "                                       image_type='shotmaps', axis=1)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
